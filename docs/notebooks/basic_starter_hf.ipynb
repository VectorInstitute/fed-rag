{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a570c4-60fe-47f2-8693-a827f9d361c6",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VectorInstitute/fed-rag/blob/main/docs/notebooks/basic_starter_hf.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "_(NOTE: if running on Colab, you will need to supply a WandB API Key in addition to your HFToken. Also, you'll need to change the runtime to a T4.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec903c3-7500-44c4-9593-d87e2cfebdb5",
   "metadata": {},
   "source": [
    "# Basic Starter Example\n",
    "\n",
    "In this notebook, we'll build a `RAGSystem` and fine-tune both the generator and retriever using the `huggingface` extra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497c18e-0c8d-4e24-9faa-b19bed277087",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d8fc1-90a3-4f8d-a68a-cd6a43572913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in a Google Colab, the first attempt at installing fed-rag may fail,\n",
    "# though for reasons unknown to me yet, if you try a second time, it magically works...\n",
    "!pip install fed-rag[huggingface] -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dc55e-d6f2-40f2-a3d2-64e304e6193d",
   "metadata": {},
   "source": [
    "## Build the RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11c5b-bd44-43c2-8150-0b3be22946de",
   "metadata": {},
   "source": [
    "### Knowledge Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753c3f4-7a84-4197-b5a0-83908308797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.knowledge_stores.in_memory import InMemoryKnowledgeStore\n",
    "from fed_rag.retrievers.huggingface.hf_sentence_transformer import (\n",
    "    HFSentenceTransformerRetriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a94db7-82be-4ee2-82f4-a8d68166959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_store = InMemoryKnowledgeStore()\n",
    "\n",
    "retriever = HFSentenceTransformerRetriever(\n",
    "    query_model_name=\"nthakur/dragon-plus-query-encoder\",\n",
    "    context_model_name=\"nthakur/dragon-plus-context-encoder\",\n",
    "    load_model_at_init=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e5aac-6615-4df1-a0a9-62d3da3a0195",
   "metadata": {},
   "source": [
    "### Let's Add Some Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfff24c-1286-4db7-a144-b2104b9320ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small sample from the Dec 2021 Wikipedia dump\n",
    "text_chunks = [\n",
    "    {\n",
    "        \"id\": \"140\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"James Cook\",\n",
    "        \"text\": \" James Cook is well known for his voyages of exploration for the British Navy in which he mapped out a significant amount of the world's uncharted waters. Cook's explorations took him around the world twice and led to countless descriptions of previously unknown plants and animals. Cook's explorations influenced many others and led to a number of scientists examining marine life more closely. Among those influenced was Charles Darwin who went on to make many contributions of his own. \",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"141\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Charles Darwin\",\n",
    "        \"text\": \" Charles Darwin, best known for his theory of evolution, made many significant contributions to the early study of marine biology. He spent much of his time from 1831 to 1836 on the voyage of HMS Beagle collecting and studying specimens from a variety of marine organisms. It was also on this expedition where Darwin began to study coral reefs and their formation. He came up with the theory that the overall growth of corals is a balance between the growth of corals upward and the sinking of the sea floor. He then came up with the idea that wherever coral atolls would be found, the central island where the coral had started to grow would be gradually subsiding\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"142\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Charles Wyville Thomson\",\n",
    "        \"text\": \" Another influential expedition was the voyage of HMS Challenger from 1872 to 1876, organized and later led by Charles Wyville Thomson. It was the first expedition purely devoted to marine science. The expedition collected and analyzed thousands of marine specimens, laying the foundation for present knowledge about life near the deep-sea floor. The findings from the expedition were a summary of the known natural, physical and chemical ocean science to that time.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"143\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Later exploration\",\n",
    "        \"text\": \" This era of marine exploration came to a close with the first and second round-the-world voyages of the Danish Galathea expeditions and Atlantic voyages by the USS Albatross, the first research vessel purpose built for marine research. These voyages further cleared the way for modern marine biology by building a base of knowledge about marine biology. This was followed by the progressive development of more advanced technologies which began to allow more extensive explorations of ocean depths that were once thought too deep to sustain life.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"144\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Marine biology labs\",\n",
    "        \"text\": \" In the 1960s and 1970s, ecological research into the life of the ocean was undertaken at institutions set up specifically to study marine biology. Notable was the Woods Hole Oceanographic Institution in America, which established a model for other marine laboratories subsequently set up around the world. Their findings of unexpectedly high species diversity in places thought to be inhabitable stimulated much theorizing by population ecologists on how high diversification could be maintained in such a food-poor and seemingly hostile environment. \",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"145\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Exploration technology\",\n",
    "        \"text\": \" In the past, the study of marine biology has been limited by a lack of technology as researchers could only go so deep to examine life in the ocean. Before the mid-twentieth century, the deep-sea bottom could not be seen unless one dredged a piece of it and brought it to the surface. This has changed dramatically due to the development of new technologies in both the laboratory and the open sea. These new technological developments have allowed scientists to explore parts of the ocean they didn't even know existed. The development of scuba gear allowed researchers to visually explore the oceans as it contains a self-contained underwater breathing apparatus allowing a person to breathe while being submerged 100 to 200 feet \",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"146\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Exploration technology\",\n",
    "        \"text\": \" the ocean. Submersibles were built like small submarines with the purpose of taking marine scientists to deeper depths of the ocean while protecting them from increasing atmospheric pressures that cause complications deep under water. The first models could hold several individuals and allowed limited visibility but enabled marine biologists to see and photograph the deeper portions of the oceans. Remotely operated underwater vehicles are now used with and without submersibles to see the deepest areas of the ocean that would be too dangerous for humans. ROVs are fully equipped with cameras and sampling equipment which allows researchers to see and control everything the vehicle does. ROVs have become the dominant type of technology used to view the deepest parts of the ocean.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"147\",\n",
    "        \"title\": \"History of marine biology\",\n",
    "        \"section\": \"Romanticization\",\n",
    "        \"text\": ' In the late 20th century and into the 21st, marine biology was \"glorified and romanticized through films and television shows,\" leading to an influx in interested students who required a damping on their enthusiasm with the day-to-day realities of the field.',\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"148\",\n",
    "        \"title\": \"Wynthryth\",\n",
    "        \"section\": \"\",\n",
    "        \"text\": \" Wynthryth of March was an early medieval saint of Anglo Saxon England. He is known to history from the Secgan Hagiography and The Confraternity Book of  St Gallen. Very little is known of his life or career. However, he was associated with the town of March, Cambridgeshire, and he may have been a relative of King Ethelstan.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"149\",\n",
    "        \"title\": \"James M. Safford\",\n",
    "        \"section\": \"\",\n",
    "        \"text\": \" James Merrill Safford (1822â€“1907) was an American geologist, chemist and university professor.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"150\",\n",
    "        \"title\": \"James M. Safford\",\n",
    "        \"section\": \"Early life\",\n",
    "        \"text\": \" James M. Safford was born in Putnam, Ohio on August 13, 1822. He received an M.D. and a PhD. He was trained as a chemist at Yale University. He married Catherine K. Owens in 1859, and they had two children.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"151\",\n",
    "        \"title\": \"James M. Safford\",\n",
    "        \"section\": \"Career\",\n",
    "        \"text\": \" Safford taught at Cumberland University in Lebanon, Tennessee from 1848 to 1873. He served as a Professor of Mineralogy, Botany, and Economical Geology at Vanderbilt University in Nashville, Tennessee from 1875 to 1900. He was a Presbyterian, and often started his lessons with a prayer. He served on the Tennessee Board of Health. Additionally, he acted as a chemist for the Tennessee Bureau of Agriculture in the 1870s and 1880s. He published fifty-four books, reports, and maps.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"152\",\n",
    "        \"title\": \"James M. Safford\",\n",
    "        \"section\": \"Death\",\n",
    "        \"text\": \" He died in Dallas on July 2, 1907.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51894e82-639e-4332-8e45-0dea7f3e3144",
   "metadata": {},
   "source": [
    "From these text chunks, we can create our `KnowledgeNodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a09878-fc4e-40a6-bdc7-e312402b7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.types import KnowledgeNode, NodeType\n",
    "\n",
    "# create knowledge nodes\n",
    "nodes = []\n",
    "texts = []\n",
    "for c in text_chunks:\n",
    "    text = c.pop(\"text\")\n",
    "    title = c.pop(\"title\")\n",
    "    section = c.pop(\"section\")\n",
    "    context_text = f\"title: {title}\\nsection: {section}\\ntext: {text}\"\n",
    "    texts.append(context_text)\n",
    "\n",
    "# batch encode\n",
    "batch_embeddings = retriever.encode_context(texts)\n",
    "\n",
    "for jx, c in enumerate(text_chunks):\n",
    "    node = KnowledgeNode(\n",
    "        embedding=batch_embeddings[jx].tolist(),\n",
    "        node_type=NodeType.TEXT,\n",
    "        text_content=texts[jx],\n",
    "        metadata=c,\n",
    "    )\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51daa4d-cd81-45a8-a766-893febb67cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae62642-0e6c-4d04-9ac1-315d169e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nodes\n",
    "knowledge_store.load_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac17ba-a86b-4a47-9aae-32cefc7cdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_store.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5247e79-3c23-446c-9d74-28dfa0075eda",
   "metadata": {},
   "source": [
    "### Define an LLM Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d885b4e-ba5d-45c0-9ccf-cd1354d7d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.generators.huggingface import HFPretrainedModelGenerator\n",
    "import torch\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "\n",
    "generation_cfg = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    eos_token_id=151643,\n",
    "    bos_token_id=151643,\n",
    "    max_new_tokens=2048,\n",
    "    top_p=0.9,\n",
    "    temperature=0.6,\n",
    "    cache_implementation=\"offloaded\",\n",
    "    stop_strings=\"</response>\",\n",
    ")\n",
    "generator = HFPretrainedModelGenerator(\n",
    "    model_name=\"Qwen/Qwen2.5-0.5B\",\n",
    "    load_model_at_init=False,\n",
    "    load_model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float16},\n",
    "    generation_config=generation_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b7ae7-6e88-4fe5-a25f-c7427e87e740",
   "metadata": {},
   "source": [
    "### Assemble the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7eb23-3d3b-4859-b818-e78692ab4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag import RAGSystem, RAGConfig\n",
    "\n",
    "rag_config = RAGConfig(top_k=2)\n",
    "rag_system = RAGSystem(\n",
    "    knowledge_store=knowledge_store,  # knowledge store loaded from knowledge_store.py\n",
    "    generator=generator,\n",
    "    retriever=retriever,\n",
    "    rag_config=rag_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a5c38-476f-402e-b1cc-aaed0c5e7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a query\n",
    "response = rag_system.query(\"Who is James Cook?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d7dd4-383c-427e-a4f2-5e65b453a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9914d1-ecac-45fe-8f9a-703d5dcd7f4e",
   "metadata": {},
   "source": [
    "## RAG Fine-tuning\n",
    "\n",
    "In this part of the notebook, we demonstrate how to fine-tune the `RAGSystem` we just built and queried. To do so, we'll use a `RetrieverTrainer` and a `GeneratorTrainer` to fine-tune the retriever and generator, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed54412-3d2e-4ecf-9c8e-fd0107433a54",
   "metadata": {},
   "source": [
    "### The Train Dataset\n",
    "\n",
    "Although the retriever and generator are trained independently, both follow a standardized process. The first step involves building the training dataset which are essentially examples of (query, response) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f863f3-c2a9-4c1a-b4b4-2f9aaafa2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_dict(\n",
    "    # examples from Commonsense QA\n",
    "    {\n",
    "        \"query\": [\n",
    "            \"The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\",\n",
    "            \"Sammy wanted to go to where the people were.  Where might he go?\",\n",
    "            \"To locate a choker not located in a jewelry box or boutique where would you go?\",\n",
    "            \"Google Maps and other highway and street GPS services have replaced what?\",\n",
    "            \"The fox walked from the city into the forest, what was it looking for?\",\n",
    "        ],\n",
    "        \"response\": [\n",
    "            \"ignore\",\n",
    "            \"populated areas\",\n",
    "            \"jewelry store\",\n",
    "            \"atlas\",\n",
    "            \"natural habitat\",\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893bdce5-871f-4200-ac3e-f4838838e54d",
   "metadata": {},
   "source": [
    "### Retriever Fine-Tuning (LSR)\n",
    "\n",
    "Here, we'll perform LM-Supervised retriever fine-tuning. For a tutorial on this trainer, see our [docs](https://vectorinstitute.github.io/fed-rag/getting_started/tutorials/lsr/).\n",
    "The `HuggingFaceTrainerForLSR` is a container class for a custom-built `~sentence_transformers.SentenceTransformerTrainer` that performs training of the retriever model using the LSR loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72343277-c463-4813-bc80-24a05eac2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.trainers.huggingface.lsr import HuggingFaceTrainerForLSR\n",
    "\n",
    "# the trainer object\n",
    "retriever_trainer = HuggingFaceTrainerForLSR(\n",
    "    rag_system=rag_system,\n",
    "    train_dataset=train_dataset,\n",
    "    # training_arguments=...  # Optional ~transformers.TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561a873-a0cf-4ac4-9163-af4e4186d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw HF trainer object\n",
    "retriever_trainer.hf_trainer_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d7a27-918c-4f9b-ac79-bb1139f1babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retriever_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3704e7f-f585-4b95-bc3f-cb0ef7935c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99763675-ef39-4cd1-a7cd-417e0367fc87",
   "metadata": {},
   "source": [
    "### Generator Fine-tuning (RALT)\n",
    "\n",
    "Here, we'll perform Retrieval-Augmented LM (Generator) fine-tuning. For a tutorial on this trainer, see our [docs](https://vectorinstitute.github.io/fed-rag/getting_started/tutorials/ralt/).\n",
    "The `HuggingFaceTrainerForRALT` is a container class for a custom-built `~transformers.Trainer` that performs training of the generator model using the causal language modelling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736288f-b9a3-4118-8f10-0637ec37999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.trainers.huggingface.ralt import HuggingFaceTrainerForRALT\n",
    "\n",
    "# the trainer object\n",
    "generator_trainer = HuggingFaceTrainerForRALT(\n",
    "    rag_system=rag_system,\n",
    "    train_dataset=train_dataset,\n",
    "    # training_arguments=...  # Optional ~transformers.TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1ed8f-236f-4e33-a5cf-7e723b3f3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw HF trainer object\n",
    "generator_trainer.hf_trainer_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03e201-b7cc-4b7a-9ce3-3ebf86532e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generator_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c1e99-8929-4542-afbb-8fc7fc2567aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ae42a-66f9-4c6a-9b31-9dcb1ec007dc",
   "metadata": {},
   "source": [
    "## Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85efe0dd-ac44-4263-b574-c35fcbb1cf44",
   "metadata": {},
   "source": [
    "In this notebook, we used a simplified example to demonstrate building and fine-tuning a RAG system with HuggingFace models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
