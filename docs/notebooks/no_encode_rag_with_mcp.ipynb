{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683e31db-0a58-43c7-bb70-efdbe655a735",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VectorInstitute/fed-rag/blob/main/docs/notebooks/no_encode_rag_with_mcp.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "_(NOTE: if running on Colab, you will need to supply a WandB API Key in addition to your HFToken. Also, you'll need to change the runtime to a T4.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c67b9-401e-4565-b082-cdc5abfbe1fe",
   "metadata": {},
   "source": [
    "# Build a NoEncode RAG System with an MCP Knowledge Store\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In traditional RAG systems, there are three components: a retriever, a knowledge store, and a generator. A user's query is encoded by the retriever and used to retrieve relevant knowledge chunks from the knowledge store that had previously been encoded by the retriever as well. The user query along with the retrieved knowledge chunks are passed to the LLM generator to finally respond to the original query.\n",
    "\n",
    "With NoEncode RAG systems, knowledge is still kept in a knowledge store and retrieved for responses to user queries, but there is no encoding step at all. Instead of pre-computing embeddings, NoEncode RAG systems query knowledge sources directly using natural language.\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "**Traditional RAG:**\n",
    "- Documents → Embed → Vector Store\n",
    "- Query → Embed → Vector Search → Retrieve → Generate\n",
    "\n",
    "**NoEncode RAG:**\n",
    "- Knowledge Sources (MCP servers, APIs, databases)\n",
    "- Query → Direct Natural Language Query → Retrieve → Generate\n",
    "\n",
    "_**NOTE:** Knowledge sources may be traditional RAG systems themselves, and thus, these would involve encoding. However, the main RAG system does not handle encoding of queries or knowledge chunks at all._\n",
    "\n",
    "### Model Context Protocol (MCP)\n",
    "\n",
    "MCP provides a standardized way for AI systems to connect to external tools and data sources. In our NoEncode RAG system, MCP servers act as live knowledge sources that can be queried directly with natural language. An MCP knowledge store acts as the MCP client host that creates connections to these servers and retrieves context from them.\n",
    "\n",
    "### Outline\n",
    "\n",
    "In this cookbook, we will stand up two MCP knowledge sources, use them as part of an MCP knowledge store, and finally build an `AsyncNoEncodeRAGSystem` that allows us to query these sources.\n",
    "\n",
    "1. MCP Knowledge Source 1: an AWS Kendra Index MCP Server\n",
    "2. MCP Knowledge Source 2: a LlamaCloud MCP Server\n",
    "3. Create an MCP Knowledge Store (using our two built sources)\n",
    "4. Assemble a NoEncode RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d1bc6-9b84-490a-8697-d502c0f5821d",
   "metadata": {},
   "source": [
    "## MCP Knowledge Source 1: an AWS Kendra Index MCP Server\n",
    "\n",
    "Here, we make use of one the myriad of officially supported [AWS MCP servers](https://github.com/awslabs/mcp?tab=readme-ov-file#available-servers) offered by [AWS Labs](https://github.com/awslabs), namely: their [AWS Kendra Index MCP Server](https://github.com/awslabs/mcp/tree/main/src/amazon-kendra-index-mcp-server).\n",
    "\n",
    "AWS Kendra is an enterprise search service powered by machine learning. It can search across various data sources including documents, FAQs, knowledge bases, and websites, providing intelligent answers to natural language queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e12826b-9652-4ac7-a3a7-d565f216eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mcp import StdioServerParameters\n",
    "from fed_rag.knowledge_stores.no_encode import MCPStdioKnowledgeSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea63aa3-1c3f-4953-a36b-72120c656912",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_params = StdioServerParameters(\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\",\n",
    "        \"--rm\",\n",
    "        \"--interactive\",\n",
    "        \"--init\",  # important!\n",
    "        \"--env-file\",\n",
    "        f\"{os.getcwd()}/.env\",\n",
    "        \"awslabs/amazon-kendra-index-mcp-server:latest\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mcp_source = MCPStdioKnowledgeSource(\n",
    "    name=\"awslabs.amazon-kendra-index-mcp-server\",\n",
    "    server_params=server_params,\n",
    "    tool_name=\"KendraQueryTool\",\n",
    "    query_param_name=\"query\",\n",
    "    tool_call_kwargs={\n",
    "        \"indexId\": \"572aca26-16be-44df-84d3-4d96d778f120\",\n",
    "        \"region\": \"ca-central-1\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c73fe-4a94-4a92-a977-1286a4671a00",
   "metadata": {},
   "source": [
    "## MCP Knowledge Source 2: a LlamaCloud MCP Server\n",
    "\n",
    "In this part of the cookbook, we'll stand up an MCP server using [LlamaCloud](https://docs.llamaindex.ai/en/stable/llama_cloud/)—an enterprise solution by LlamaIndex—by following their MCP [demo](https://github.com/run-llama/llamacloud-mcp?tab=readme-ov-file#llamacloud-as-an-mcp-server).\n",
    "\n",
    "LlamaCloud provides document parsing, indexing, and retrieval capabilities. By exposing these through an MCP server, we can query processed documents directly using natural language without managing our own document processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237356f3-a651-49ec-8acd-d81ed9ef3890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9af79-f756-4bb7-8d1b-d9bd0262c8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb002cfc-17eb-4dae-bb2c-9240f220866d",
   "metadata": {},
   "source": [
    "## Create an MCP Knowledge Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0264333-a34e-46ec-8c20-8b4faf6d8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.knowledge_stores.no_encode import MCPKnowledgeStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547a02e4-bcee-4d99-b14a-6ddd1ced685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_store = MCPKnowledgeStore().add_source(mcp_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885761e1-dc1a-4ef5-8b01-f33083ff01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await knowledge_store.retrieve(\"What is RAFT\", top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1ff0463-3e93-4548-8eb1-7a15e604671e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In this paper, we present Retrieval Augmented\\nFine Tuning (RAFT), a training recipe which improves the model’s ability\\nto answer questions in \"open-book\" in-domain settings. In training RAFT,\\ngiven a question, and a set of retrieved documents, we train the model to\\nignore those documents that don’t ',\n",
       " '3 RAFT\\n\\n\\nIn this section, we present RAFT, a novel way of training LLMs for domain-specific open-\\nbook exams. We first introduce the classical technique of supervised fine-tuning, followed\\nwith the key takeaways from our experiments. Then, we introduce RAFT , a modified\\nversion of general instructio',\n",
       " ', 2023; Xu\\n\\n\\n9\\n\\n\\n\\n\\n\\n\\n\\nPreprint, Under Review\\n\\n\\net al., 2023; Liu et al., 2024). These works focus on constructing a combination of finetuning\\ndataset for RAG and train a model to perform well on these tasks. In particular, in their\\nsettings, at test time, the domain or documents can be different tha',\n",
       " '...Fine Tuning (RAFT), a training recipe which improves the model’s ability\\nto answer questions in \"open-book\" in-domain settings. In training RAFT,\\ngiven a question, and a set of retrieved documents, we train the model to\\nignore those documents that don’t help in answering the question, which...',\n",
       " '...r6gd.metal | r6gd.medium | r6gd.large | r6gd.xlarge | r6gd.2xlarge | r6gd.4xlarge\\n                                                | r6gd.8xlarge | r6gd.12xlarge | r6gd.16xlarge | x1.16xlarge | x1.32xlarge...',\n",
       " '...AWS SDK for C...',\n",
       " '...instanceId\\n                                             \\n\\t\\n                                          \\n                                          The ID of the instance...',\n",
       " '...ServiceToken\": \"arn:aws:lambda:us-east-2:123456789012:function:lambda-error-processor-primer-14ROR2T3JKU66\",\\n        \"FunctionName\": \"lambda-error-processor-randomerror-ZWUC391MQAJK...',\n",
       " '...from the event parameter.\\n    console.log(\"Reading options from event:\\\\n\", util.inspect(event, {depth: 5}));\\n    const srcBucket = event.Records[0].s3.bucket.name;\\n    // Object key may have spaces or unicode non-ASCII characters...',\n",
       " \"...dependencies {\\n    implementation 'com.amazonaws:aws-lambda-java-core:1.2.1'\\n    implementation 'com.amazonaws:aws-lambda-java-events:3.1.0'\\n    runtimeOnly 'com.amazonaws:aws-lambda-java-log4j2:1.2.0'\\n}...\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "contents = json.loads(res[0][1].text_content)\n",
    "\n",
    "excerpts = [r[\"excerpt\"] for r in contents[\"results\"]]\n",
    "excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9c1307e-6c67-428f-b902-065d9381b6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0b4c5d59-3ce4-465e-bec4-e59b009bfaf2-25ef4adc-ed88-4ffa-bfd9-f70966cc6c11',\n",
       " 'type': 'ANSWER',\n",
       " 'document_title': 'raft.pdf',\n",
       " 'document_uri': 'https://fed-rag-mcp-cookbook.s3.ca-central-1.amazonaws.com/raft.pdf',\n",
       " 'score': 'HIGH',\n",
       " 'excerpt': 'In this paper, we present Retrieval Augmented\\nFine Tuning (RAFT), a training recipe which improves the model’s ability\\nto answer questions in \"open-book\" in-domain settings. In training RAFT,\\ngiven a question, and a set of retrieved documents, we train the model to\\nignore those documents that don’t ',\n",
       " 'additional_attributes': [{'Key': 'AnswerText',\n",
       "   'ValueType': 'TEXT_WITH_HIGHLIGHTS_VALUE',\n",
       "   'Value': {'TextWithHighlightsValue': {'Text': 'In this paper, we present Retrieval Augmented\\nFine Tuning (RAFT), a training recipe which improves the model’s ability\\nto answer questions in \"open-book\" in-domain settings. In training RAFT,\\ngiven a question, and a set of retrieved documents, we train the model to\\nignore those documents that don’t help in answering the question, which\\nwe call, distractor documents. RAFT accomplishes this by citing verbatim\\nthe right sequence from the relevant document to help answer the question.\\nThis coupled with RAFT’s chain-of-thought-style response helps improve\\nthe model’s ability to reason.',\n",
       "     'Highlights': [{'BeginOffset': 26,\n",
       "       'EndOffset': 57,\n",
       "       'TopAnswer': False,\n",
       "       'Type': 'STANDARD'},\n",
       "      {'BeginOffset': 59,\n",
       "       'EndOffset': 63,\n",
       "       'TopAnswer': False,\n",
       "       'Type': 'STANDARD'},\n",
       "      {'BeginOffset': 186,\n",
       "       'EndOffset': 190,\n",
       "       'TopAnswer': False,\n",
       "       'Type': 'STANDARD'},\n",
       "      {'BeginOffset': 369,\n",
       "       'EndOffset': 373,\n",
       "       'TopAnswer': False,\n",
       "       'Type': 'STANDARD'},\n",
       "      {'BeginOffset': 504,\n",
       "       'EndOffset': 508,\n",
       "       'TopAnswer': False,\n",
       "       'Type': 'STANDARD'}]}}}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[\"results\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d4539-3e89-4632-b4f3-3c892b14f4a5",
   "metadata": {},
   "source": [
    "## Assemble a NoEncode RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d626460-d28f-488f-8bb1-738cf389e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.generators.huggingface import HFPretrainedModelGenerator\n",
    "import torch\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "\n",
    "generation_cfg = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    eos_token_id=151643,\n",
    "    bos_token_id=151643,\n",
    "    max_new_tokens=2048,\n",
    "    top_p=0.9,\n",
    "    temperature=0.6,\n",
    "    cache_implementation=\"offloaded\",\n",
    "    stop_strings=\"</response>\",\n",
    ")\n",
    "generator = HFPretrainedModelGenerator(\n",
    "    model_name=\"Qwen/Qwen2.5-0.5B\",\n",
    "    load_model_at_init=False,\n",
    "    load_model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float16},\n",
    "    generation_config=generation_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d24ee6-b734-489b-8750-39aea560b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag import AsyncNoEncodeRAGSystem, RAGConfig\n",
    "\n",
    "rag_config = RAGConfig(top_k=2)\n",
    "rag_system = AsyncNoEncodeRAGSystem(\n",
    "    knowledge_store=knowledge_store,  # knowledge store loaded from knowledge_store.py\n",
    "    generator=generator,\n",
    "    rag_config=rag_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b69b6-4d05-49e7-9952-6f05c7257f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "res = await rag_system.query(query=\"What is RAFT?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c86d1fcd-501b-43f7-911d-5578a02f8218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SourceNode(score=1.0, node=KnowledgeNode(node_id='75916b23-e63e-460c-b11b-5ded44e47b79', embedding=None, node_type=<NodeType.TEXT: 'text'>, text_content='{\"query\": \"What is RAFT?\", \"total_results_count\": 92, \"results\": [{\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-c08e3baf-263e-497f-9f8e-6a498a48b7cd\", \"type\": \"ANSWER\", \"document_title\": \"raft.pdf\", \"document_uri\": \"https://fed-rag-mcp-cookbook.s3.ca-central-1.amazonaws.com/raft.pdf\", \"score\": \"HIGH\", \"excerpt\": \"In this paper, we present Retrieval Augmented\\\\nFine Tuning (RAFT), a training recipe which improves the model\\\\u2019s ability\\\\nto answer questions in \\\\\"open-book\\\\\" in-domain settings. In training RAFT,\\\\ngiven a question, and a set of retrieved documents, we train the model to\\\\nignore those documents that don\\\\u2019t \", \"additional_attributes\": [{\"Key\": \"AnswerText\", \"ValueType\": \"TEXT_WITH_HIGHLIGHTS_VALUE\", \"Value\": {\"TextWithHighlightsValue\": {\"Text\": \"In this paper, we present Retrieval Augmented\\\\nFine Tuning (RAFT), a training recipe which improves the model\\\\u2019s ability\\\\nto answer questions in \\\\\"open-book\\\\\" in-domain settings. In training RAFT,\\\\ngiven a question, and a set of retrieved documents, we train the model to\\\\nignore those documents that don\\\\u2019t help in answering the question, which\\\\nwe call, distractor documents. RAFT accomplishes this by citing verbatim\\\\nthe right sequence from the relevant document to help answer the question.\\\\nThis coupled with RAFT\\\\u2019s chain-of-thought-style response helps improve\\\\nthe model\\\\u2019s ability to reason.\", \"Highlights\": [{\"BeginOffset\": 26, \"EndOffset\": 57, \"TopAnswer\": false, \"Type\": \"STANDARD\"}, {\"BeginOffset\": 59, \"EndOffset\": 63, \"TopAnswer\": false, \"Type\": \"STANDARD\"}, {\"BeginOffset\": 186, \"EndOffset\": 190, \"TopAnswer\": false, \"Type\": \"STANDARD\"}, {\"BeginOffset\": 369, \"EndOffset\": 373, \"TopAnswer\": false, \"Type\": \"STANDARD\"}, {\"BeginOffset\": 504, \"EndOffset\": 508, \"TopAnswer\": false, \"Type\": \"STANDARD\"}]}}}]}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-cd68d5a6-e61d-435f-89c4-bc0b3d76ff20\", \"type\": \"ANSWER\", \"document_title\": \"raft.pdf\", \"document_uri\": \"https://fed-rag-mcp-cookbook.s3.ca-central-1.amazonaws.com/raft.pdf\", \"score\": \"MEDIUM\", \"excerpt\": \"3 RAFT\\\\n\\\\n\\\\nIn this section, we present RAFT, a novel way of training LLMs for domain-specific open-\\\\nbook exams. We first introduce the classical technique of supervised fine-tuning, followed\\\\nwith the key takeaways from our experiments. Then, we introduce RAFT , a modified\\\\nversion of general instructio\", \"additional_attributes\": [{\"Key\": \"AnswerText\", \"ValueType\": \"TEXT_WITH_HIGHLIGHTS_VALUE\", \"Value\": {\"TextWithHighlightsValue\": {\"Text\": \"3 RAFT\\\\n\\\\n\\\\nIn this section, we present RAFT, a novel way of training LLMs for domain-specific open-\\\\nbook exams. We first introduce the classical technique of supervised fine-tuning, followed\\\\nwith the key takeaways from our experiments. Then, we introduce RAFT , a modified\\\\nversion of general instruction tuning. Lastly, we provide an overview of the experiments to\\\\nexpect in the later sections.\\\\n\\\\n\\\\nSupervised Finetuning\\\\n\\\\n\\\\nConsider the supervised fine-tuning (SFT) setting for a Question-Answer dataset.\", \"Highlights\": [{\"BeginOffset\": 2, \"EndOffset\": 6, \"TopAnswer\": false, \"Type\": \"STANDARD\"}, {\"BeginOffset\": 37, \"EndOffset\": 41, \"TopAnswer\": false, \"Type\": \"STANDARD\"}, {\"BeginOffset\": 253, \"EndOffset\": 257, \"TopAnswer\": false, \"Type\": \"STANDARD\"}]}}}]}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-ed9e135f-88ea-4f2e-821c-51417e6e336b\", \"type\": \"ANSWER\", \"document_title\": \"raft.pdf\", \"document_uri\": \"https://fed-rag-mcp-cookbook.s3.ca-central-1.amazonaws.com/raft.pdf\", \"score\": \"MEDIUM\", \"excerpt\": \", 2023; Xu\\\\n\\\\n\\\\n9\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPreprint, Under Review\\\\n\\\\n\\\\net al., 2023; Liu et al., 2024). These works focus on constructing a combination of finetuning\\\\ndataset for RAG and train a model to perform well on these tasks. In particular, in their\\\\nsettings, at test time, the domain or documents can be different tha\", \"additional_attributes\": [{\"Key\": \"AnswerText\", \"ValueType\": \"TEXT_WITH_HIGHLIGHTS_VALUE\", \"Value\": {\"TextWithHighlightsValue\": {\"Text\": \", 2023; Xu\\\\n\\\\n\\\\n9\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPreprint, Under Review\\\\n\\\\n\\\\net al., 2023; Liu et al., 2024). These works focus on constructing a combination of finetuning\\\\ndataset for RAG and train a model to perform well on these tasks. In particular, in their\\\\nsettings, at test time, the domain or documents can be different than the training time;\\\\nwhereas our paper studies a slightly opposite scenario where we only care about testing the\\\\nLLM on the same set of documents.\\\\n\\\\n\\\\n7 Conclusion\\\\n\\\\n\\\\nRAFT is a training strategy designed to enhance the model\\\\u2019s performance in answering\\\\nquestions within a specific domain, in \\\\\"open-book\\\\\" settings.\", \"Highlights\": [{\"BeginOffset\": 464, \"EndOffset\": 468, \"TopAnswer\": false, \"Type\": \"STANDARD\"}]}}}]}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-38555c81-4292-4d35-a90a-9885b5643510\", \"type\": \"DOCUMENT\", \"document_title\": \"raft.pdf\", \"document_uri\": \"https://fed-rag-mcp-cookbook.s3.ca-central-1.amazonaws.com/raft.pdf\", \"score\": \"VERY_HIGH\", \"excerpt\": \"...Fine Tuning (RAFT), a training recipe which improves the model\\\\u2019s ability\\\\nto answer questions in \\\\\"open-book\\\\\" in-domain settings. In training RAFT,\\\\ngiven a question, and a set of retrieved documents, we train the model to\\\\nignore those documents that don\\\\u2019t help in answering the question, which...\", \"additional_attributes\": []}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-9a35d244-33c8-4e81-9cd0-bba28b42124c\", \"type\": \"DOCUMENT\", \"document_title\": \"Instance - Amazon Elastic Compute Cloud\", \"document_uri\": \"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_Instance.html\", \"score\": \"MEDIUM\", \"excerpt\": \"...instanceId\\\\n                                             \\\\n\\\\t\\\\n                                          \\\\n                                          The ID of the instance...\", \"additional_attributes\": []}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-ee77aea5-514a-497a-9130-e9d6bb5f87cb\", \"type\": \"DOCUMENT\", \"document_title\": \"RequestSpotLaunchSpecification - Amazon Elastic Compute Cloud\", \"document_uri\": \"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RequestSpotLaunchSpecification.html\", \"score\": \"MEDIUM\", \"excerpt\": \"...r6gd.metal | r6gd.medium | r6gd.large | r6gd.xlarge | r6gd.2xlarge | r6gd.4xlarge\\\\n                                                | r6gd.8xlarge | r6gd.12xlarge | r6gd.16xlarge | x1.16xlarge | x1.32xlarge...\", \"additional_attributes\": []}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-f9070a27-2ba6-42d4-a991-da9a43ad5543\", \"type\": \"DOCUMENT\", \"document_title\": \"Using AWS Lambda with AWS CloudFormation - AWS Lambda\", \"document_uri\": \"http://docs.aws.amazon.com/lambda/latest/dg/services-cloudformation.html\", \"score\": \"MEDIUM\", \"excerpt\": \"...ServiceToken\\\\\": \\\\\"arn:aws:lambda:us-east-2:123456789012:function:lambda-error-processor-primer-14ROR2T3JKU66\\\\\",\\\\n        \\\\\"FunctionName\\\\\": \\\\\"lambda-error-processor-randomerror-ZWUC391MQAJK...\", \"additional_attributes\": []}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-b554b5f6-73ba-4fb8-9f5a-82a727333b5b\", \"type\": \"DOCUMENT\", \"document_title\": \"Sample Amazon S3 function code - AWS Lambda\", \"document_uri\": \"http://docs.aws.amazon.com/lambda/latest/dg/with-s3-example-deployment-pkg.html\", \"score\": \"MEDIUM\", \"excerpt\": \"...from the event parameter.\\\\n    console.log(\\\\\"Reading options from event:\\\\\\\\n\\\\\", util.inspect(event, {depth: 5}));\\\\n    const srcBucket = event.Records[0].s3.bucket.name;\\\\n    // Object key may have spaces or unicode non-ASCII characters...\", \"additional_attributes\": []}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-87b1976b-987c-4d10-8223-4fce648762d8\", \"type\": \"DOCUMENT\", \"document_title\": \"AWS Lambda deployment package in Java - AWS Lambda\", \"document_uri\": \"http://docs.aws.amazon.com/lambda/latest/dg/java-package.html\", \"score\": \"MEDIUM\", \"excerpt\": \"...dependencies {\\\\n    implementation \\'com.amazonaws:aws-lambda-java-core:1.2.1\\'\\\\n    implementation \\'com.amazonaws:aws-lambda-java-events:3.1.0\\'\\\\n    runtimeOnly \\'com.amazonaws:aws-lambda-java-log4j2:1.2.0\\'\\\\n}...\", \"additional_attributes\": []}, {\"id\": \"7e0ec195-1811-41f7-aa55-2089111779e1-dc375e98-cd03-4889-8985-8bee1e30f8fd\", \"type\": \"DOCUMENT\", \"document_title\": \"LaunchSpecification - Amazon Elastic Compute Cloud\", \"document_uri\": \"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_LaunchSpecification.html\", \"score\": \"MEDIUM\", \"excerpt\": \"...Describes the launch specification for an instance.\\\\n\\\\n                                 \\\\n                                 Contents...\", \"additional_attributes\": []}]}', image_content=None, metadata={'server_params': {'command': 'docker', 'args': ['run', '--rm', '--interactive', '--init', '--env-file', '/home/nerdai/Projects/fed-rag/docs/notebooks/.env', 'awslabs/amazon-kendra-index-mcp-server:latest'], 'env': None, 'cwd': None, 'encoding': 'utf-8', 'encoding_error_handler': 'strict'}, 'name': 'awslabs.amazon-kendra-index-mcp-server', 'tool_name': 'KendraQueryTool', 'query_param_name': 'query', 'tool_call_kwargs': {'indexId': '572aca26-16be-44df-84d3-4d96d778f120', 'region': 'ca-central-1'}}))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7e44f-11ed-48a7-b601-a1bca3908f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
