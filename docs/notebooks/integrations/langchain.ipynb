{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78004a67-2dea-4da4-a87f-819fde322364",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VectorInstitute/fed-rag/blob/main/docs/notebooks/integrations/langchain.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "_(NOTE: if running on Colab, you will need to supply a WandB API Key in addition to your HFToken. Also, you'll need to change the runtime to a T4.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31024c3-3f4f-4909-94c2-ef5bc7de1f5a",
   "metadata": {},
   "source": [
    "# Using LangChain for Inference\n",
    "\n",
    "## Introduction\n",
    "\n",
    "After fine-tuning your RAG system to achieve desired performance, you'll want to\n",
    "deploy it for inference. While FedRAG's `RAGSystem` provides complete inference\n",
    "capabilities out of the box, you may need additional features for production deployments\n",
    "or want to leverage the ecosystem of existing RAG frameworks.\n",
    "\n",
    "FedRAG offers a seamless integration into [LangChain](https://github.com/langchain-ai/langchain) through our bridges system, giving you the best of both worlds: FedRAG's fine-tuning capabilities combined\n",
    "with the extensive inference features of LangChain.\n",
    "\n",
    "In this example, we demonstrate how you can convert a `RAGSystem` into a tuple consisting of `~langchain_core.vectorstores.VectorStore` and `~langchain_core.language_models.BaseLLM`. The former can then be transformed into a `~langchain_core.vectorestores.VectorStoreRetriever` using the `as_retriever()` method, enabling the creation of a complete QA pipeline whith LangChain's LCEL.\n",
    "\n",
    "__NOTE:__\n",
    "Streaming and async functionalities are not yet supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248dec17-5225-4d16-8aad-00c0101c7a4b",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad8f32-d63a-4b9f-8406-79130df4945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in a Google Colab, the first attempt at installing fed-rag may fail,\n",
    "# though for reasons unknown to me yet, if you try a second time, it magically works...\n",
    "!pip install fed-rag[huggingface,langchain] -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0e246-6757-4c67-98b8-347173d186b7",
   "metadata": {},
   "source": [
    "## Setup â€” The RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf7eae4-e5c8-4f97-8a82-a8c4ddbaea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.generation.configuration_utils import GenerationConfig\n",
    "\n",
    "from fed_rag import RAGSystem, RAGConfig\n",
    "from fed_rag.generators.huggingface import HFPretrainedModelGenerator\n",
    "from fed_rag.retrievers.huggingface import (\n",
    "    HFSentenceTransformerRetriever,\n",
    ")\n",
    "from fed_rag.knowledge_stores import InMemoryKnowledgeStore\n",
    "from fed_rag.data_structures import KnowledgeNode\n",
    "\n",
    "\n",
    "QUERY_ENCODER_NAME = \"nthakur/dragon-plus-query-encoder\"\n",
    "CONTEXT_ENCODER_NAME = \"nthakur/dragon-plus-context-encoder\"\n",
    "PRETRAINED_MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# Retriever\n",
    "retriever = HFSentenceTransformerRetriever(\n",
    "    query_model_name=QUERY_ENCODER_NAME,\n",
    "    context_model_name=CONTEXT_ENCODER_NAME,\n",
    "    load_model_at_init=False,\n",
    ")\n",
    "\n",
    "# Generator\n",
    "generation_cfg = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    eos_token_id=151643,\n",
    "    bos_token_id=151643,\n",
    "    max_new_tokens=2048,\n",
    "    top_p=0.9,\n",
    "    temperature=0.6,\n",
    "    cache_implementation=\"offloaded\",\n",
    "    stop_strings=\"</response>\",\n",
    ")\n",
    "generator = HFPretrainedModelGenerator(\n",
    "    model_name=PRETRAINED_MODEL_NAME,\n",
    "    load_model_at_init=False,\n",
    "    load_model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float16},\n",
    "    generation_config=generation_cfg,\n",
    ")\n",
    "\n",
    "# Knowledge store\n",
    "knowledge_store = InMemoryKnowledgeStore()\n",
    "\n",
    "\n",
    "# Create the RAG system\n",
    "rag_system = RAGSystem(\n",
    "    retriever=retriever,\n",
    "    generator=generator,\n",
    "    knowledge_store=knowledge_store,\n",
    "    rag_config=RAGConfig(top_k=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2f188-5a6c-4092-834e-b45d321a1eba",
   "metadata": {},
   "source": [
    "### Add some knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c13ca5a-83da-44af-9bc9-c75274856248",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = [\n",
    "    \"Retrieval-Augmented Generation (RAG) combines retrieval with generation.\",\n",
    "    \"LLMs can hallucinate information when they lack context.\",\n",
    "]\n",
    "knowledge_nodes = [\n",
    "    KnowledgeNode(\n",
    "        node_type=\"text\",\n",
    "        embedding=retriever.encode_context(ct).tolist(),\n",
    "        text_content=ct,\n",
    "    )\n",
    "    for ct in text_chunks\n",
    "]\n",
    "knowledge_store.load_nodes(knowledge_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0389b3-da82-4e37-915a-1326a4573b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_system.knowledge_store.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df7a0b-b0f2-45b3-9cc8-c9d7d8997056",
   "metadata": {},
   "source": [
    "## Using the Bridge\n",
    "\n",
    "Converting your RAG system to LangChain objects is seamless since the bridge\n",
    "functionality is already built into the `RAGSystem` class. The `RAGSystem` inherits\n",
    "from `LangChainBridgeMixin`, which provides the `to_langchain()` method for\n",
    "effortless conversion.\n",
    "\n",
    "__NOTE__: The `to_langchain()` method returns a tuple consisting of `FedRAGVectorStore` and `FedRAGLLM` objects, which are custom implementation of the `~langchain_core.vectorstores.VectorStore` and `~langchain_core.language_models.BaseLLM` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87648b84-00a2-4bb1-b30e-07b5b9a090b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: LLMs can hallucinate information when they lack context., Score: 0.5453173113645673\n",
      "Content: Retrieval-Augmented Generation (RAG) combines retrieval with generation., Score: 0.5065647593667755\n",
      "--------------------------------------------------------------------------------\n",
      "Content: LLMs can hallucinate information when they lack context.\n",
      "Content: Retrieval-Augmented Generation (RAG) combines retrieval with generation.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bd85c326ff420ea124f41ef89a3a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6b8c18bfab497188bdfb109946ec3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2356829f451c4267ba7dadbc7608080c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e0e748cb3e4f199149fcd8b8fbac4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f4a3aee52f4deda05fac59e489dfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7712f18ccd41cbad988b1df69a8aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ccec33377343b7a8693dd2b196f53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'top_k': 20, 'pad_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An autonomous agent is a system designed to perform specific tasks without direct human intervention. It uses AI to process information and make decisions based on that information. Autonomous agents can be used in various applications, such as healthcare, finance, and logistics, to improve efficiency and accuracy.\n",
      "</response>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the LangChain objects\n",
    "vector_store, llm = rag_system.to_langchain()\n",
    "\n",
    "# Search the vectore store directly\n",
    "query = \"What happens if LLMs lack context?\"\n",
    "results = vector_store.similarity_search_with_score(query, k=2)\n",
    "for doc, score in results:\n",
    "    print(f\"Content: {doc.page_content}, Score: {score}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Or, convert it to a retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "results = retriever.invoke(query)\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Or, create a complete RAG chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from fed_rag.base.generator import DEFAULT_PROMPT_TEMPLATE\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vector_store.as_retriever() | format_docs,\n",
    "        \"query\": RunnablePassthrough(),\n",
    "    }\n",
    "    | PromptTemplate.from_template(DEFAULT_PROMPT_TEMPLATE)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = qa_chain.invoke(\"What are autonomous agents?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a3335-66ec-47a3-ac2f-1592a6496b72",
   "metadata": {},
   "source": [
    "### Modifying Knowledge\n",
    "\n",
    "In addition to querying the bridged index, you can also make changes to the\n",
    "underlying KnowledgeStore using LangChains's API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39707b5a-82e1-4977-be72-96ce9f6714d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6797e6f0-5501-447b-ad8a-f256f97bde9b',\n",
       " 'aa0af869-44fa-4c50-b151-eb4c46d311e3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = vector_store.add_texts(\n",
    "    texts=[\"some arbitrary text\", \"some other arbitrary text\"],\n",
    "    metadatas=[{\"source\": \"fed-rag\"}, {\"source\": \"fed-rag\"}],\n",
    ")\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1bb880-a526-4dd7-8751-06f08689092d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that what we added above is indeed in the knowledge store\n",
    "rag_system.knowledge_store.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2febaa2d-d28f-46d2-8de7-741fe28f322f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also delete nodes\n",
    "vector_store.delete(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc736ec-6dff-4c54-b145-8c65592a68c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that what we deleted above is indeed removed from the knowledge store\n",
    "rag_system.knowledge_store.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d26a2-ae85-425d-81d3-bb613f25e8ad",
   "metadata": {},
   "source": [
    "## Bridge Metadata\n",
    "\n",
    "To view the metadata of the LangChain bridge, you can access the class attribute\n",
    "`bridge` of the `RAGSystem` class, which is a dictionary object that contains the `BridgeMetadata` for all of the installed bridges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49206bb2-1fec-491d-9099-aa3b74fd181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llama-index-core': {'bridge_version': '0.1.0', 'framework': 'llama-index-core', 'compatible_versions': {'min': '0.12.35'}, 'method_name': 'to_llamaindex'}, 'langchain-core': {'bridge_version': '0.1.0', 'framework': 'langchain-core', 'compatible_versions': {'min': '0.3.62'}, 'method_name': 'to_langchain'}}\n",
      "{'bridge_version': '0.1.0', 'framework': 'langchain-core', 'compatible_versions': {'min': '0.3.62'}, 'method_name': 'to_langchain'}\n"
     ]
    }
   ],
   "source": [
    "# see available bridges\n",
    "print(RAGSystem.bridges)\n",
    "\n",
    "# see the LangChain bridge metadata\n",
    "print(RAGSystem.bridges[\"langchain-core\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
