{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683e31db-0a58-43c7-bb70-efdbe655a735",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VectorInstitute/fed-rag/blob/main/docs/notebooks/basic_fl.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "__IMPORTANT NOTE__: As this notebook requires the running of a Docker image, it is not runnable from within a Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5e360-118b-4535-86ba-8e612f0f0d98",
   "metadata": {},
   "source": [
    "# Basic Federated Fine-tuning of RAG Systems\n",
    "\n",
    "In this notebook, we demonstrate how to perform federated RAG fine-tuning with FedRAG. Specifically, we'll apply federated learning to fine-tune the generator of a RAG system using a federated setting that comprises two clients.\n",
    "\n",
    "__HARDWARE REQUIREMENTS:__ This notebook requires a setup with at least two GPUs each having at least 12GB of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca01feb-259d-4dfd-a925-785aa0bd3780",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc462746-4abe-42e3-a9e9-3914df55a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install fed-rag[huggingface,qdrant] docker -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc03c8-50ea-4621-95cf-f3daddc4f65c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Running this notebook requires two high-level steps.\n",
    "\n",
    "1. Running the knowledge store Qdrant service via Docker\n",
    "2. Downloading the associated example Python script, which defines the `RAGSystem` as well as the `FLTask` which we use to launch the federated learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193d780-9a08-4fa2-8071-98efa1bb9fc3",
   "metadata": {},
   "source": [
    "## Running the Qdrant knowledge store service\n",
    "\n",
    "We have previously prepared a knowledge store Qdrant service that comes pre-populated with knowledge artifacts from the December 2021 Wikipedia dump (i.e., Izacard, Gautier, et al. \"Few-shot learning with retrieval augmented language models.\" arXiv preprint arXiv:2208.03299 1.2 (2022): 4.).\n",
    "\n",
    "Executing the below command will run this docker image on the host machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b7b0a9-505e-4737-be5b-4b8d881eef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 'vectorinstitute/qdrant-atlas-dec-wiki-2021:latest' already exists locally\n",
      "Container started with ID: 8e58b42f14a508109055e20dc5f0d066fce8b4775f4b3a9b98b758239ce19b6e\n",
      "Container status: running\n",
      "Container logs:\n",
      "Starting Qdrant Atlas Knowledge Store container\n",
      "Running database initialization check...\n",
      "Using tiny sample mode...\n",
      "Creating tiny sample file for testing...\n",
      "Using tiny sample file: tiny-sample.jsonl\n",
      "Verifying sample file creation...\n",
      "âœ… Sample file successfully created at: /app/data/atlas/enwiki-dec2021/tiny-sample.jsonl\n",
      "File details:\n",
      "-rw-r--r-- 1 root root 6785 Jun  8 03:35 /app/data/atlas/enwiki-dec2021/tiny-sample.jsonl\n",
      "File content (first 3 lines):\n",
      "{\"id\": \"140\", \"title\": \"History of marine biology\", \"section\": \"James Cook\", \"text\": \" James Cook is well known for his voyages of exploration for the British Navy in which he mapped out a significant amount of the world's uncharted waters. Cook's explorations took him around the world twice and led to countless descriptions of previously unknown plants and animals. Cook's explorations influenced many others and led to a number of scientists examining marine life more closely. Among those influenced was Charles Darwin who went on to make many contributions of his own. \"}\n",
      "{\"id\": \"141\", \"title\": \"History of marine biology\", \"section\": \"Charles Darwin\", \"text\": \" Charles Darwin, best known for his theory of evolution, made many significant contributions to the early study of marine biology. He spent much of his time from 1831 to 1836 on the voyage of HMS Beagle collecting and studying specimens from a variety of marine organisms. It was also on this expedition where Darwin began to study coral reefs and their formation. He came up with the theory that the overall growth of corals is a balance between the growth of corals upward and the sinking of the sea floor. He then came up with the idea that wherever coral atolls would be found, the central island where the coral had started to grow would be gradually subsiding\"}\n",
      "{\"id\": \"142\", \"title\": \"History of marine biology\", \"section\": \"Charles Wyville Thomson\", \"text\": \" Another influential expedition was the voyage of HMS Challenger from 1872 to 1876, organized and later led by Charles Wyville Thomson. It was the first expedition purely devoted to marine science. The expedition collected and analyzed thousands of marine specimens, laying the foundation for present knowledge about life near the deep-sea floor. The findings from the expedition were a summary of the known natural, physical and chemical ocean science to that time.\"}\n",
      "Directory listing:\n",
      "total 16\n",
      "drwxr-xr-x 2 root root 4096 Jun  8 03:35 .\n",
      "drwxr-xr-x 3 root root 4096 Jun  8 03:35 ..\n",
      "-rw-r--r-- 1 root root 6785 Jun  8 03:35 tiny-sample.jsonl\n",
      "Starting Qdrant service for initialization...\n",
      "Waiting for Qdrant service to be ready...\n",
      "Waiting for Qdrant to start... (Attempt 1/30)\n",
      "           _                 _    \n",
      "  __ _  __| |_ __ __ _ _ __ | |_  \n",
      " / _` |/ _` | '__/ _` | '_ \\| __| \n",
      "| (_| | (_| | | | (_| | | | | |_  \n",
      " \\__, |\\__,_|_|  \\__,_|_| |_|\\__| \n",
      "    |_|                           \n",
      "\n",
      "Version: 1.14.0, build: 3617a011\n",
      "Access web UI at http://localhost:6333/dashboard\n",
      "\n",
      "2025-06-08T03:35:27.950637Z  INFO storage::content_manager::consensus::persistent: Initializing new raft state at ./storage/raft_state.json    \n",
      "2025-06-08T03:35:27.986913Z  INFO qdrant: Distributed mode disabled    \n",
      "2025-06-08T03:35:27.986975Z  INFO qdrant: Telemetry reporting enabled, id: 625917b8-775f-4afa-b0e3-b10768d40bb4    \n",
      "2025-06-08T03:35:27.987060Z  INFO qdrant: Inference service is not configured.    \n",
      "2025-06-08T03:35:27.989443Z  INFO qdrant::actix: TLS disabled for REST API    \n",
      "2025-06-08T03:35:27.989564Z  INFO qdrant::actix: Qdrant HTTP listening on 6333    \n",
      "2025-06-08T03:35:27.989603Z  INFO actix_server::builder: Starting 11 workers\n",
      "2025-06-08T03:35:27.989615Z  INFO actix_server::server: Actix runtime found; starting in Actix runtime\n",
      "2025-06-08T03:35:27.999766Z  INFO qdrant::tonic: Qdrant gRPC listening on 6334    \n",
      "2025-06-08T03:35:27.999792Z  INFO qdrant::tonic: TLS disabled for gRPC API    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import docker\n",
    "import os\n",
    "import time\n",
    "\n",
    "client = docker.from_env()\n",
    "image_name = \"vectorinstitute/qdrant-atlas-dec-wiki-2021:latest\"\n",
    "\n",
    "# first see if we need to pull the docker image\n",
    "try:\n",
    "    client.images.get(image_name)\n",
    "    print(f\"Image '{image_name}' already exists locally\")\n",
    "except docker.errors.ImageNotFound:\n",
    "    print(f\"Image '{image_name}' not found locally. Pulling...\")\n",
    "    # Pull with progress information\n",
    "    for line in client.api.pull(image_name, stream=True, decode=True):\n",
    "        if \"progress\" in line:\n",
    "            print(f\"\\r{line['status']}: {line['progress']}\", end=\"\")\n",
    "        elif \"status\" in line:\n",
    "            print(f\"\\r{line['status']}\", end=\"\")\n",
    "    print(\"\\nPull complete!\")\n",
    "\n",
    "# run the Qdrant container\n",
    "container = client.containers.run(\n",
    "    \"vectorinstitute/qdrant-atlas-dec-wiki-2021:latest\",\n",
    "    detach=True,  # -d flag\n",
    "    name=\"tiny-wiki-dec2021-ks\",  # --name\n",
    "    ports={\"6333/tcp\": 6333, \"6334/tcp\": 6334},  # -p 6333:6333  # -p 6334:6334\n",
    "    volumes={\n",
    "        \"qdrant_data\": {  # -v qdrant_data:/qdrant_storage\n",
    "            \"bind\": \"/qdrant_storage\",\n",
    "            \"mode\": \"rw\",\n",
    "        }\n",
    "    },\n",
    "    environment={\"SAMPLE_SIZE\": \"tiny\"},  # -e SAMPLE_SIZE=tiny\n",
    "    device_requests=[\n",
    "        docker.types.DeviceRequest(\n",
    "            count=-1, capabilities=[[\"gpu\"]]\n",
    "        )  # --gpus all\n",
    "    ],\n",
    "    remove=False,  # Don't auto-remove when stopped\n",
    ")\n",
    "\n",
    "print(f\"Container started with ID: {container.id}\")\n",
    "\n",
    "# wait a moment for the container to initialize\n",
    "time.sleep(3)\n",
    "\n",
    "# Check container status\n",
    "container.reload()  # Refresh container data\n",
    "print(f\"Container status: {container.status}\")\n",
    "print(f\"Container logs:\")\n",
    "print(container.logs().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dab9e-c337-461a-8616-046915b7af25",
   "metadata": {},
   "source": [
    "### Check if the service is ready\n",
    "\n",
    "To check if the knowledge store service is ready to be used, we can create a `QdrantKnowledgeStore` with the correct collection name and check if the collection exists. If it does, then we're ready to carry on with the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3327c44-a8ac-4e13-a828-a1075c80edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.knowledge_stores import QdrantKnowledgeStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1322316-80ad-4150-ae28-da468219c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = QdrantKnowledgeStore(\n",
    "    collection_name=\"nthakur.dragon-plus-context-encoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef532a8-5608-426e-b44a-34a88f35c860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the collection exists, this should return an int.\n",
    "# Otherwise, it will raise an error\n",
    "ks.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb82562-d609-408b-a342-bd750e01b9a9",
   "metadata": {},
   "source": [
    "## Download the example Python script which builds the RAG System and FL Task\n",
    "\n",
    "This script can be found in the main Github repo for fed-rag and within the `example_scripts` subdirectory. More specifically:\n",
    "\n",
    "<https://github.com/VectorInstitute/fed-rag/blob/main/example_scripts/cookbook_script-basic_fl.py>\n",
    "\n",
    "The commands below will download the script's text, display it here for convenience and then write it to a local file that we can execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cbc275-f03d-47ae-b00a-5f58d9082b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_URL = \"https://raw.githubusercontent.com/VectorInstitute/fed-rag/refs/heads/main/example_scripts/cookbook_script-basic_fl.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c97bfc3-be0d-439e-bcbe-1b4517fb3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(SCRIPT_URL)\n",
    "rag_code = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eea9dd8-63ad-4f4c-8ad8-ba7f77b991de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">logging</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">INFO</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">typing</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Literal</span>\n",
       "\n",
       "<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">torch</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">datasets</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Dataset</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">flwr.common.logger</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">log</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">transformers.generation.utils</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">GenerationConfig</span>\n",
       "\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">RAGConfig</span><span class=\"p\">,</span> <span class=\"n\">RAGSystem</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.fl_tasks.huggingface</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"p\">(</span>\n",
       "    <span class=\"n\">HuggingFaceFlowerClient</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">HuggingFaceFlowerServer</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.generators</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HFPretrainedModelGenerator</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.knowledge_stores</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">QdrantKnowledgeStore</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.retrievers</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HFSentenceTransformerRetriever</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.trainer_managers.huggingface</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.trainers.huggingface.ralt</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HuggingFaceTrainerForRALT</span>\n",
       "\n",
       "<span class=\"n\">GRPC_MAX_MESSAGE_LENGTH</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mi\">512</span> <span class=\"o\">*</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"mf\">3.75</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">PEFT_MODEL_NAME</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;Styxxxx/llama2_7b_lora-quac&quot;</span>\n",
       "<span class=\"n\">BASE_MODEL_NAME</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;meta-llama/Llama-2-7b-hf&quot;</span>\n",
       "<span class=\"n\">TRAIN_DATASET</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_dict</span><span class=\"p\">(</span>\n",
       "    <span class=\"c1\"># examples from Commonsense QA</span>\n",
       "    <span class=\"p\">{</span>\n",
       "        <span class=\"s2\">&quot;query&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;Sammy wanted to go to where the people were.  Where might he go?&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;To locate a choker not located in a jewelry box or boutique where would you go?&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;Google Maps and other highway and street GPS services have replaced what?&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">],</span>\n",
       "        <span class=\"s2\">&quot;response&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;populated areas&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;jewelry store&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;atlas&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">],</span>\n",
       "    <span class=\"p\">}</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"n\">VAL_DATASET</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_dict</span><span class=\"p\">(</span>\n",
       "    <span class=\"p\">{</span>\n",
       "        <span class=\"s2\">&quot;query&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;The fox walked from the city into the forest, what was it looking for?&quot;</span>\n",
       "        <span class=\"p\">],</span>\n",
       "        <span class=\"s2\">&quot;response&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;natural habitat&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">],</span>\n",
       "    <span class=\"p\">}</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">get_trainer_manager</span><span class=\"p\">(</span><span class=\"n\">server</span><span class=\"p\">:</span> <span class=\"nb\">bool</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># use the knowledge store in image: vectorinstitute/qdrant-atlas-dec-wiki-2021:latest</span>\n",
       "    <span class=\"n\">knowledge_store</span> <span class=\"o\">=</span> <span class=\"n\">QdrantKnowledgeStore</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">collection_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;nthakur.dragon-plus-context-encoder&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"n\">retriever</span> <span class=\"o\">=</span> <span class=\"n\">HFSentenceTransformerRetriever</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">query_model_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;nthakur/dragon-plus-query-encoder&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">context_model_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;nthakur/dragon-plus-context-encoder&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">load_model_at_init</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># LLM generator</span>\n",
       "    <span class=\"n\">generation_cfg</span> <span class=\"o\">=</span> <span class=\"n\">GenerationConfig</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">do_sample</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">eos_token_id</span><span class=\"o\">=</span><span class=\"mi\">151643</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">bos_token_id</span><span class=\"o\">=</span><span class=\"mi\">151643</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">max_new_tokens</span><span class=\"o\">=</span><span class=\"mi\">2048</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">top_p</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mf\">0.6</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">cache_implementation</span><span class=\"o\">=</span><span class=\"s2\">&quot;offloaded&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">stop_strings</span><span class=\"o\">=</span><span class=\"s2\">&quot;&lt;/response&gt;&quot;</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">server</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">load_model_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">&quot;device_map&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;cpu&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;torch_dtype&quot;</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">}</span>\n",
       "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">load_model_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n",
       "            <span class=\"s2\">&quot;device_map&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;auto&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;torch_dtype&quot;</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">}</span>\n",
       "    <span class=\"n\">generator</span> <span class=\"o\">=</span> <span class=\"n\">HFPretrainedModelGenerator</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;Qwen/Qwen2.5-0.5B&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">load_model_at_init</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">load_model_kwargs</span><span class=\"o\">=</span><span class=\"n\">load_model_kwargs</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">generation_config</span><span class=\"o\">=</span><span class=\"n\">generation_cfg</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># assemble rag system</span>\n",
       "    <span class=\"n\">rag_config</span> <span class=\"o\">=</span> <span class=\"n\">RAGConfig</span><span class=\"p\">(</span><span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">rag_system</span> <span class=\"o\">=</span> <span class=\"n\">RAGSystem</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">knowledge_store</span><span class=\"o\">=</span><span class=\"n\">knowledge_store</span><span class=\"p\">,</span>  <span class=\"c1\"># knowledge store loaded from knowledge_store.py</span>\n",
       "        <span class=\"n\">generator</span><span class=\"o\">=</span><span class=\"n\">generator</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">retriever</span><span class=\"o\">=</span><span class=\"n\">retriever</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">rag_config</span><span class=\"o\">=</span><span class=\"n\">rag_config</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># the trainer object</span>\n",
       "    <span class=\"n\">generator_trainer</span> <span class=\"o\">=</span> <span class=\"n\">HuggingFaceTrainerForRALT</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">rag_system</span><span class=\"o\">=</span><span class=\"n\">rag_system</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">train_dataset</span><span class=\"o\">=</span><span class=\"n\">TRAIN_DATASET</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"c1\"># trainer manager object</span>\n",
       "    <span class=\"n\">manager</span> <span class=\"o\">=</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s2\">&quot;generator&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">generator_trainer</span><span class=\"o\">=</span><span class=\"n\">generator_trainer</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">manager</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">build_client</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">train_manager</span><span class=\"p\">:</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">HuggingFaceFlowerClient</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">fl_task</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">get_federated_task</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">model</span>\n",
       "    <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">INFO</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;loaded generator is on: </span><span class=\"si\">{</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">fl_task</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">train_dataset</span><span class=\"o\">=</span><span class=\"n\">TRAIN_DATASET</span><span class=\"p\">,</span> <span class=\"n\">val_dataset</span><span class=\"o\">=</span><span class=\"n\">VAL_DATASET</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">build_server</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">train_manager</span><span class=\"p\">:</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">HuggingFaceFlowerServer</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">fl_task</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">get_federated_task</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">model</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">fl_task</span><span class=\"o\">.</span><span class=\"n\">server</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">main</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">component</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s2\">&quot;server&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client_0&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client_1&quot;</span><span class=\"p\">],</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;For starting any of the FL Task components.</span>\n",
       "\n",
       "<span class=\"sd\">    IMPORTANT NOTE: This script requires the Dec. 2021 Wikipedia Qdrant knowledge</span>\n",
       "<span class=\"sd\">    store to be up an running. Use the shell command below to run the docker image.</span>\n",
       "\n",
       "<span class=\"sd\">        ```sh</span>\n",
       "<span class=\"sd\">        docker run --gpus all -d \\</span>\n",
       "<span class=\"sd\">        --name qdrant-ra-dit \\</span>\n",
       "<span class=\"sd\">        -p 6333:6333 \\</span>\n",
       "<span class=\"sd\">        -p 6334:6334 \\</span>\n",
       "<span class=\"sd\">        -v qdrant_data:/qdrant_storage \\</span>\n",
       "<span class=\"sd\">        -e SAMPLE_SIZE=tiny \\</span>\n",
       "<span class=\"sd\">        vectorinstitute/qdrant-atlas-dec-wiki-2021</span>\n",
       "<span class=\"sd\">        ```</span>\n",
       "\n",
       "<span class=\"sd\">    MAIN USAGE:</span>\n",
       "<span class=\"sd\">        ## server</span>\n",
       "<span class=\"sd\">        `uv run python example_scripts/cookbook_script-basic_fl.py --component server`</span>\n",
       "\n",
       "<span class=\"sd\">        ## client 1</span>\n",
       "<span class=\"sd\">        `uv run python example_scripts/cookbook_script-basic_fl.py --component client_0`</span>\n",
       "\n",
       "<span class=\"sd\">        ## client 1</span>\n",
       "<span class=\"sd\">        `uv run python example_scripts/cookbook_script-basic_fl.py --component client_1`</span>\n",
       "<span class=\"sd\">    &quot;&quot;&quot;</span>\n",
       "    <span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">flwr</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">fl</span>\n",
       "\n",
       "    <span class=\"k\">if</span> <span class=\"n\">component</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;server&quot;</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">manager</span> <span class=\"o\">=</span> <span class=\"n\">get_trainer_manager</span><span class=\"p\">(</span><span class=\"n\">server</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">server</span> <span class=\"o\">=</span> <span class=\"n\">build_server</span><span class=\"p\">(</span><span class=\"n\">manager</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">fl</span><span class=\"o\">.</span><span class=\"n\">server</span><span class=\"o\">.</span><span class=\"n\">start_server</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">server</span><span class=\"o\">=</span><span class=\"n\">server</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">server_address</span><span class=\"o\">=</span><span class=\"s2\">&quot;[::]:8080&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">grpc_max_message_length</span><span class=\"o\">=</span><span class=\"n\">GRPC_MAX_MESSAGE_LENGTH</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "    <span class=\"k\">elif</span> <span class=\"n\">component</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s2\">&quot;client_0&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client_1&quot;</span><span class=\"p\">]:</span>\n",
       "        <span class=\"n\">manager</span> <span class=\"o\">=</span> <span class=\"n\">get_trainer_manager</span><span class=\"p\">(</span><span class=\"n\">server</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">build_client</span><span class=\"p\">(</span><span class=\"n\">manager</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">fl</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">start_client</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">client</span><span class=\"o\">=</span><span class=\"n\">client</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">server_address</span><span class=\"o\">=</span><span class=\"s2\">&quot;[::]:8080&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">grpc_max_message_length</span><span class=\"o\">=</span><span class=\"n\">GRPC_MAX_MESSAGE_LENGTH</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span><span class=\"s2\">&quot;Unrecognized component.&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">fire</span>\n",
       "\n",
       "    <span class=\"n\">fire</span><span class=\"o\">.</span><span class=\"n\">Fire</span><span class=\"p\">(</span><span class=\"n\">main</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{logging}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{INFO}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{typing}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{Literal}\n",
       "\n",
       "\\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{torch}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{datasets}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{Dataset}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{flwr}\\PY{n+nn}{.}\\PY{n+nn}{common}\\PY{n+nn}{.}\\PY{n+nn}{logger}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{log}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{transformers}\\PY{n+nn}{.}\\PY{n+nn}{generation}\\PY{n+nn}{.}\\PY{n+nn}{utils}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{GenerationConfig}\n",
       "\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{RAGConfig}\\PY{p}{,} \\PY{n}{RAGSystem}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{fl\\PYZus{}tasks}\\PY{n+nn}{.}\\PY{n+nn}{huggingface}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{p}{(}\n",
       "    \\PY{n}{HuggingFaceFlowerClient}\\PY{p}{,}\n",
       "    \\PY{n}{HuggingFaceFlowerServer}\\PY{p}{,}\n",
       "\\PY{p}{)}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{generators}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HFPretrainedModelGenerator}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{knowledge\\PYZus{}stores}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{QdrantKnowledgeStore}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{retrievers}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HFSentenceTransformerRetriever}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{trainer\\PYZus{}managers}\\PY{n+nn}{.}\\PY{n+nn}{huggingface}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HuggingFaceRAGTrainerManager}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{trainers}\\PY{n+nn}{.}\\PY{n+nn}{huggingface}\\PY{n+nn}{.}\\PY{n+nn}{ralt}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HuggingFaceTrainerForRALT}\n",
       "\n",
       "\\PY{n}{GRPC\\PYZus{}MAX\\PYZus{}MESSAGE\\PYZus{}LENGTH} \\PY{o}{=} \\PY{n+nb}{int}\\PY{p}{(}\\PY{l+m+mi}{512} \\PY{o}{*} \\PY{l+m+mi}{1024} \\PY{o}{*} \\PY{l+m+mi}{1024} \\PY{o}{*} \\PY{l+m+mf}{3.75}\\PY{p}{)}\n",
       "\\PY{n}{PEFT\\PYZus{}MODEL\\PYZus{}NAME} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Styxxxx/llama2\\PYZus{}7b\\PYZus{}lora\\PYZhy{}quac}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "\\PY{n}{BASE\\PYZus{}MODEL\\PYZus{}NAME} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{meta\\PYZhy{}llama/Llama\\PYZhy{}2\\PYZhy{}7b\\PYZhy{}hf}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "\\PY{n}{TRAIN\\PYZus{}DATASET} \\PY{o}{=} \\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}dict}\\PY{p}{(}\n",
       "    \\PY{c+c1}{\\PYZsh{} examples from Commonsense QA}\n",
       "    \\PY{p}{\\PYZob{}}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{query}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Sammy wanted to go to where the people were.  Where might he go?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{To locate a choker not located in a jewelry box or boutique where would you go?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Google Maps and other highway and street GPS services have replaced what?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{response}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{populated areas}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{jewelry store}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{atlas}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "    \\PY{p}{\\PYZcb{}}\n",
       "\\PY{p}{)}\n",
       "\\PY{n}{VAL\\PYZus{}DATASET} \\PY{o}{=} \\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}dict}\\PY{p}{(}\n",
       "    \\PY{p}{\\PYZob{}}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{query}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{The fox walked from the city into the forest, what was it looking for?}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{response}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{natural habitat}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "    \\PY{p}{\\PYZcb{}}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{get\\PYZus{}trainer\\PYZus{}manager}\\PY{p}{(}\\PY{n}{server}\\PY{p}{:} \\PY{n+nb}{bool}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} use the knowledge store in image: vectorinstitute/qdrant\\PYZhy{}atlas\\PYZhy{}dec\\PYZhy{}wiki\\PYZhy{}2021:latest}\n",
       "    \\PY{n}{knowledge\\PYZus{}store} \\PY{o}{=} \\PY{n}{QdrantKnowledgeStore}\\PY{p}{(}\n",
       "        \\PY{n}{collection\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{nthakur.dragon\\PYZhy{}plus\\PYZhy{}context\\PYZhy{}encoder}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{timeout}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{n}{retriever} \\PY{o}{=} \\PY{n}{HFSentenceTransformerRetriever}\\PY{p}{(}\n",
       "        \\PY{n}{query\\PYZus{}model\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{nthakur/dragon\\PYZhy{}plus\\PYZhy{}query\\PYZhy{}encoder}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{context\\PYZus{}model\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{nthakur/dragon\\PYZhy{}plus\\PYZhy{}context\\PYZhy{}encoder}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}at\\PYZus{}init}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} LLM generator}\n",
       "    \\PY{n}{generation\\PYZus{}cfg} \\PY{o}{=} \\PY{n}{GenerationConfig}\\PY{p}{(}\n",
       "        \\PY{n}{do\\PYZus{}sample}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,}\n",
       "        \\PY{n}{eos\\PYZus{}token\\PYZus{}id}\\PY{o}{=}\\PY{l+m+mi}{151643}\\PY{p}{,}\n",
       "        \\PY{n}{bos\\PYZus{}token\\PYZus{}id}\\PY{o}{=}\\PY{l+m+mi}{151643}\\PY{p}{,}\n",
       "        \\PY{n}{max\\PYZus{}new\\PYZus{}tokens}\\PY{o}{=}\\PY{l+m+mi}{2048}\\PY{p}{,}\n",
       "        \\PY{n}{top\\PYZus{}p}\\PY{o}{=}\\PY{l+m+mf}{0.9}\\PY{p}{,}\n",
       "        \\PY{n}{temperature}\\PY{o}{=}\\PY{l+m+mf}{0.6}\\PY{p}{,}\n",
       "        \\PY{n}{cache\\PYZus{}implementation}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{offloaded}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{stop\\PYZus{}strings}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZlt{}/response\\PYZgt{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{k}{if} \\PY{n}{server}\\PY{p}{:}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}kwargs} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{device\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{cpu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{torch\\PYZus{}dtype}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{float16}\\PY{p}{\\PYZcb{}}\n",
       "    \\PY{k}{else}\\PY{p}{:}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}kwargs} \\PY{o}{=} \\PY{p}{\\PYZob{}}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{device\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{auto}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{torch\\PYZus{}dtype}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{float16}\\PY{p}{,}\n",
       "        \\PY{p}{\\PYZcb{}}\n",
       "    \\PY{n}{generator} \\PY{o}{=} \\PY{n}{HFPretrainedModelGenerator}\\PY{p}{(}\n",
       "        \\PY{n}{model\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Qwen/Qwen2.5\\PYZhy{}0.5B}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}at\\PYZus{}init}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{,}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}kwargs}\\PY{o}{=}\\PY{n}{load\\PYZus{}model\\PYZus{}kwargs}\\PY{p}{,}\n",
       "        \\PY{n}{generation\\PYZus{}config}\\PY{o}{=}\\PY{n}{generation\\PYZus{}cfg}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} assemble rag system}\n",
       "    \\PY{n}{rag\\PYZus{}config} \\PY{o}{=} \\PY{n}{RAGConfig}\\PY{p}{(}\\PY{n}{top\\PYZus{}k}\\PY{o}{=}\\PY{l+m+mi}{2}\\PY{p}{)}\n",
       "    \\PY{n}{rag\\PYZus{}system} \\PY{o}{=} \\PY{n}{RAGSystem}\\PY{p}{(}\n",
       "        \\PY{n}{knowledge\\PYZus{}store}\\PY{o}{=}\\PY{n}{knowledge\\PYZus{}store}\\PY{p}{,}  \\PY{c+c1}{\\PYZsh{} knowledge store loaded from knowledge\\PYZus{}store.py}\n",
       "        \\PY{n}{generator}\\PY{o}{=}\\PY{n}{generator}\\PY{p}{,}\n",
       "        \\PY{n}{retriever}\\PY{o}{=}\\PY{n}{retriever}\\PY{p}{,}\n",
       "        \\PY{n}{rag\\PYZus{}config}\\PY{o}{=}\\PY{n}{rag\\PYZus{}config}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} the trainer object}\n",
       "    \\PY{n}{generator\\PYZus{}trainer} \\PY{o}{=} \\PY{n}{HuggingFaceTrainerForRALT}\\PY{p}{(}\n",
       "        \\PY{n}{rag\\PYZus{}system}\\PY{o}{=}\\PY{n}{rag\\PYZus{}system}\\PY{p}{,}\n",
       "        \\PY{n}{train\\PYZus{}dataset}\\PY{o}{=}\\PY{n}{TRAIN\\PYZus{}DATASET}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{c+c1}{\\PYZsh{} trainer manager object}\n",
       "    \\PY{n}{manager} \\PY{o}{=} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{(}\n",
       "        \\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{generator}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{generator\\PYZus{}trainer}\\PY{o}{=}\\PY{n}{generator\\PYZus{}trainer}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{manager}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{build\\PYZus{}client}\\PY{p}{(}\n",
       "    \\PY{n}{train\\PYZus{}manager}\\PY{p}{:} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{HuggingFaceFlowerClient}\\PY{p}{:}\n",
       "    \\PY{n}{fl\\PYZus{}task} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{get\\PYZus{}federated\\PYZus{}task}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{model} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{model}\n",
       "    \\PY{n}{log}\\PY{p}{(}\\PY{n}{INFO}\\PY{p}{,} \\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{loaded generator is on: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{model}\\PY{o}{.}\\PY{n}{device}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{fl\\PYZus{}task}\\PY{o}{.}\\PY{n}{client}\\PY{p}{(}\n",
       "        \\PY{n}{model}\\PY{o}{=}\\PY{n}{model}\\PY{p}{,} \\PY{n}{train\\PYZus{}dataset}\\PY{o}{=}\\PY{n}{TRAIN\\PYZus{}DATASET}\\PY{p}{,} \\PY{n}{val\\PYZus{}dataset}\\PY{o}{=}\\PY{n}{VAL\\PYZus{}DATASET}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{build\\PYZus{}server}\\PY{p}{(}\n",
       "    \\PY{n}{train\\PYZus{}manager}\\PY{p}{:} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{HuggingFaceFlowerServer}\\PY{p}{:}\n",
       "    \\PY{n}{fl\\PYZus{}task} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{get\\PYZus{}federated\\PYZus{}task}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{model} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{model}\n",
       "    \\PY{k}{return} \\PY{n}{fl\\PYZus{}task}\\PY{o}{.}\\PY{n}{server}\\PY{p}{(}\\PY{n}{model}\\PY{o}{=}\\PY{n}{model}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{main}\\PY{p}{(}\n",
       "    \\PY{n}{component}\\PY{p}{:} \\PY{n}{Literal}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{server}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{k+kc}{None}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}For starting any of the FL Task components.}\n",
       "\n",
       "\\PY{l+s+sd}{    IMPORTANT NOTE: This script requires the Dec. 2021 Wikipedia Qdrant knowledge}\n",
       "\\PY{l+s+sd}{    store to be up an running. Use the shell command below to run the docker image.}\n",
       "\n",
       "\\PY{l+s+sd}{        ```sh}\n",
       "\\PY{l+s+sd}{        docker run \\PYZhy{}\\PYZhy{}gpus all \\PYZhy{}d \\PYZbs{}}\n",
       "\\PY{l+s+sd}{        \\PYZhy{}\\PYZhy{}name qdrant\\PYZhy{}ra\\PYZhy{}dit \\PYZbs{}}\n",
       "\\PY{l+s+sd}{        \\PYZhy{}p 6333:6333 \\PYZbs{}}\n",
       "\\PY{l+s+sd}{        \\PYZhy{}p 6334:6334 \\PYZbs{}}\n",
       "\\PY{l+s+sd}{        \\PYZhy{}v qdrant\\PYZus{}data:/qdrant\\PYZus{}storage \\PYZbs{}}\n",
       "\\PY{l+s+sd}{        \\PYZhy{}e SAMPLE\\PYZus{}SIZE=tiny \\PYZbs{}}\n",
       "\\PY{l+s+sd}{        vectorinstitute/qdrant\\PYZhy{}atlas\\PYZhy{}dec\\PYZhy{}wiki\\PYZhy{}2021}\n",
       "\\PY{l+s+sd}{        ```}\n",
       "\n",
       "\\PY{l+s+sd}{    MAIN USAGE:}\n",
       "\\PY{l+s+sd}{        \\PYZsh{}\\PYZsh{} server}\n",
       "\\PY{l+s+sd}{        `uv run python example\\PYZus{}scripts/cookbook\\PYZus{}script\\PYZhy{}basic\\PYZus{}fl.py \\PYZhy{}\\PYZhy{}component server`}\n",
       "\n",
       "\\PY{l+s+sd}{        \\PYZsh{}\\PYZsh{} client 1}\n",
       "\\PY{l+s+sd}{        `uv run python example\\PYZus{}scripts/cookbook\\PYZus{}script\\PYZhy{}basic\\PYZus{}fl.py \\PYZhy{}\\PYZhy{}component client\\PYZus{}0`}\n",
       "\n",
       "\\PY{l+s+sd}{        \\PYZsh{}\\PYZsh{} client 1}\n",
       "\\PY{l+s+sd}{        `uv run python example\\PYZus{}scripts/cookbook\\PYZus{}script\\PYZhy{}basic\\PYZus{}fl.py \\PYZhy{}\\PYZhy{}component client\\PYZus{}1`}\n",
       "\\PY{l+s+sd}{    \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{flwr}\\PY{+w}{ }\\PY{k}{as}\\PY{+w}{ }\\PY{n+nn}{fl}\n",
       "\n",
       "    \\PY{k}{if} \\PY{n}{component} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{server}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "        \\PY{n}{manager} \\PY{o}{=} \\PY{n}{get\\PYZus{}trainer\\PYZus{}manager}\\PY{p}{(}\\PY{n}{server}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "        \\PY{n}{server} \\PY{o}{=} \\PY{n}{build\\PYZus{}server}\\PY{p}{(}\\PY{n}{manager}\\PY{p}{)}\n",
       "        \\PY{n}{fl}\\PY{o}{.}\\PY{n}{server}\\PY{o}{.}\\PY{n}{start\\PYZus{}server}\\PY{p}{(}\n",
       "            \\PY{n}{server}\\PY{o}{=}\\PY{n}{server}\\PY{p}{,}\n",
       "            \\PY{n}{server\\PYZus{}address}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{[::]:8080}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{grpc\\PYZus{}max\\PYZus{}message\\PYZus{}length}\\PY{o}{=}\\PY{n}{GRPC\\PYZus{}MAX\\PYZus{}MESSAGE\\PYZus{}LENGTH}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "    \\PY{k}{elif} \\PY{n}{component} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "        \\PY{n}{manager} \\PY{o}{=} \\PY{n}{get\\PYZus{}trainer\\PYZus{}manager}\\PY{p}{(}\\PY{n}{server}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
       "        \\PY{n}{client} \\PY{o}{=} \\PY{n}{build\\PYZus{}client}\\PY{p}{(}\\PY{n}{manager}\\PY{p}{)}\n",
       "        \\PY{n}{fl}\\PY{o}{.}\\PY{n}{client}\\PY{o}{.}\\PY{n}{start\\PYZus{}client}\\PY{p}{(}\n",
       "            \\PY{n}{client}\\PY{o}{=}\\PY{n}{client}\\PY{p}{,}\n",
       "            \\PY{n}{server\\PYZus{}address}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{[::]:8080}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{grpc\\PYZus{}max\\PYZus{}message\\PYZus{}length}\\PY{o}{=}\\PY{n}{GRPC\\PYZus{}MAX\\PYZus{}MESSAGE\\PYZus{}LENGTH}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "    \\PY{k}{else}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{ValueError}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Unrecognized component.}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{fire}\n",
       "\n",
       "    \\PY{n}{fire}\\PY{o}{.}\\PY{n}{Fire}\\PY{p}{(}\\PY{n}{main}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from logging import INFO\n",
       "from typing import Literal\n",
       "\n",
       "import torch\n",
       "from datasets import Dataset\n",
       "from flwr.common.logger import log\n",
       "from transformers.generation.utils import GenerationConfig\n",
       "\n",
       "from fed_rag import RAGConfig, RAGSystem\n",
       "from fed_rag.fl_tasks.huggingface import (\n",
       "    HuggingFaceFlowerClient,\n",
       "    HuggingFaceFlowerServer,\n",
       ")\n",
       "from fed_rag.generators import HFPretrainedModelGenerator\n",
       "from fed_rag.knowledge_stores import QdrantKnowledgeStore\n",
       "from fed_rag.retrievers import HFSentenceTransformerRetriever\n",
       "from fed_rag.trainer_managers.huggingface import HuggingFaceRAGTrainerManager\n",
       "from fed_rag.trainers.huggingface.ralt import HuggingFaceTrainerForRALT\n",
       "\n",
       "GRPC_MAX_MESSAGE_LENGTH = int(512 * 1024 * 1024 * 3.75)\n",
       "PEFT_MODEL_NAME = \"Styxxxx/llama2_7b_lora-quac\"\n",
       "BASE_MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
       "TRAIN_DATASET = Dataset.from_dict(\n",
       "    # examples from Commonsense QA\n",
       "    {\n",
       "        \"query\": [\n",
       "            \"The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\",\n",
       "            \"Sammy wanted to go to where the people were.  Where might he go?\",\n",
       "            \"To locate a choker not located in a jewelry box or boutique where would you go?\",\n",
       "            \"Google Maps and other highway and street GPS services have replaced what?\",\n",
       "        ],\n",
       "        \"response\": [\n",
       "            \"ignore\",\n",
       "            \"populated areas\",\n",
       "            \"jewelry store\",\n",
       "            \"atlas\",\n",
       "        ],\n",
       "    }\n",
       ")\n",
       "VAL_DATASET = Dataset.from_dict(\n",
       "    {\n",
       "        \"query\": [\n",
       "            \"The fox walked from the city into the forest, what was it looking for?\"\n",
       "        ],\n",
       "        \"response\": [\n",
       "            \"natural habitat\",\n",
       "        ],\n",
       "    }\n",
       ")\n",
       "\n",
       "\n",
       "def get_trainer_manager(server: bool) -> HuggingFaceRAGTrainerManager:\n",
       "    # use the knowledge store in image: vectorinstitute/qdrant-atlas-dec-wiki-2021:latest\n",
       "    knowledge_store = QdrantKnowledgeStore(\n",
       "        collection_name=\"nthakur.dragon-plus-context-encoder\",\n",
       "        timeout=10,\n",
       "    )\n",
       "    retriever = HFSentenceTransformerRetriever(\n",
       "        query_model_name=\"nthakur/dragon-plus-query-encoder\",\n",
       "        context_model_name=\"nthakur/dragon-plus-context-encoder\",\n",
       "        load_model_at_init=False,\n",
       "    )\n",
       "\n",
       "    # LLM generator\n",
       "    generation_cfg = GenerationConfig(\n",
       "        do_sample=True,\n",
       "        eos_token_id=151643,\n",
       "        bos_token_id=151643,\n",
       "        max_new_tokens=2048,\n",
       "        top_p=0.9,\n",
       "        temperature=0.6,\n",
       "        cache_implementation=\"offloaded\",\n",
       "        stop_strings=\"</response>\",\n",
       "    )\n",
       "    if server:\n",
       "        load_model_kwargs = {\"device_map\": \"cpu\", \"torch_dtype\": torch.float16}\n",
       "    else:\n",
       "        load_model_kwargs = {\n",
       "            \"device_map\": \"auto\",\n",
       "            \"torch_dtype\": torch.float16,\n",
       "        }\n",
       "    generator = HFPretrainedModelGenerator(\n",
       "        model_name=\"Qwen/Qwen2.5-0.5B\",\n",
       "        load_model_at_init=False,\n",
       "        load_model_kwargs=load_model_kwargs,\n",
       "        generation_config=generation_cfg,\n",
       "    )\n",
       "\n",
       "    # assemble rag system\n",
       "    rag_config = RAGConfig(top_k=2)\n",
       "    rag_system = RAGSystem(\n",
       "        knowledge_store=knowledge_store,  # knowledge store loaded from knowledge_store.py\n",
       "        generator=generator,\n",
       "        retriever=retriever,\n",
       "        rag_config=rag_config,\n",
       "    )\n",
       "\n",
       "    # the trainer object\n",
       "    generator_trainer = HuggingFaceTrainerForRALT(\n",
       "        rag_system=rag_system,\n",
       "        train_dataset=TRAIN_DATASET,\n",
       "    )\n",
       "    # trainer manager object\n",
       "    manager = HuggingFaceRAGTrainerManager(\n",
       "        mode=\"generator\",\n",
       "        generator_trainer=generator_trainer,\n",
       "    )\n",
       "    return manager\n",
       "\n",
       "\n",
       "def build_client(\n",
       "    train_manager: HuggingFaceRAGTrainerManager,\n",
       ") -> HuggingFaceFlowerClient:\n",
       "    fl_task = train_manager.get_federated_task()\n",
       "    model = train_manager.model\n",
       "    log(INFO, f\"loaded generator is on: {model.device}\")\n",
       "    return fl_task.client(\n",
       "        model=model, train_dataset=TRAIN_DATASET, val_dataset=VAL_DATASET\n",
       "    )\n",
       "\n",
       "\n",
       "def build_server(\n",
       "    train_manager: HuggingFaceRAGTrainerManager,\n",
       ") -> HuggingFaceFlowerServer:\n",
       "    fl_task = train_manager.get_federated_task()\n",
       "    model = train_manager.model\n",
       "    return fl_task.server(model=model)\n",
       "\n",
       "\n",
       "def main(\n",
       "    component: Literal[\"server\", \"client_0\", \"client_1\"],\n",
       ") -> None:\n",
       "    \"\"\"For starting any of the FL Task components.\n",
       "\n",
       "    IMPORTANT NOTE: This script requires the Dec. 2021 Wikipedia Qdrant knowledge\n",
       "    store to be up an running. Use the shell command below to run the docker image.\n",
       "\n",
       "        ```sh\n",
       "        docker run --gpus all -d \\\n",
       "        --name qdrant-ra-dit \\\n",
       "        -p 6333:6333 \\\n",
       "        -p 6334:6334 \\\n",
       "        -v qdrant_data:/qdrant_storage \\\n",
       "        -e SAMPLE_SIZE=tiny \\\n",
       "        vectorinstitute/qdrant-atlas-dec-wiki-2021\n",
       "        ```\n",
       "\n",
       "    MAIN USAGE:\n",
       "        ## server\n",
       "        `uv run python example_scripts/cookbook_script-basic_fl.py --component server`\n",
       "\n",
       "        ## client 1\n",
       "        `uv run python example_scripts/cookbook_script-basic_fl.py --component client_0`\n",
       "\n",
       "        ## client 1\n",
       "        `uv run python example_scripts/cookbook_script-basic_fl.py --component client_1`\n",
       "    \"\"\"\n",
       "    import flwr as fl\n",
       "\n",
       "    if component == \"server\":\n",
       "        manager = get_trainer_manager(server=True)\n",
       "        server = build_server(manager)\n",
       "        fl.server.start_server(\n",
       "            server=server,\n",
       "            server_address=\"[::]:8080\",\n",
       "            grpc_max_message_length=GRPC_MAX_MESSAGE_LENGTH,\n",
       "        )\n",
       "    elif component in [\"client_0\", \"client_1\"]:\n",
       "        manager = get_trainer_manager(server=False)\n",
       "        client = build_client(manager)\n",
       "        fl.client.start_client(\n",
       "            client=client,\n",
       "            server_address=\"[::]:8080\",\n",
       "            grpc_max_message_length=GRPC_MAX_MESSAGE_LENGTH,\n",
       "        )\n",
       "    else:\n",
       "        raise ValueError(\"Unrecognized component.\")\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    import fire\n",
       "\n",
       "    fire.Fire(main)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Code, display\n",
    "\n",
    "display(Code(rag_code, language=\"python\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbcff1-96f1-4664-9da6-b84aa43d6347",
   "metadata": {},
   "source": [
    "## Federated fine-tuning\n",
    "\n",
    "The script displayed above shows the `RAGSystem` and the generator trainer task that we will federate next. To do this we will:\n",
    "\n",
    "1. Write the script text to a file\n",
    "2. Launch the server and two clients in their own separate subprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21c091c-094b-4ac9-9da4-443edec578ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the script's code to a Python file on disk\n",
    "with open(\"rag_federated_learning.py\", \"w\") as f:\n",
    "    f.write(rag_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31161647-6ae2-454a-8f90-0130e5df5626",
   "metadata": {},
   "source": [
    "With a file written to our local disk, we can run the script to launch the FL servers and clients. We will use a notebook utility class called `ProcessMonitor` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2392c8-2002-41ac-a2bb-c0638e0ef361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.utils.notebook import ProcessMonitor\n",
    "\n",
    "monitor = ProcessMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea1773a-6c61-4170-839f-61334f6657fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch server command\n",
    "server_command = \"python rag_federated_learning.py --component server\"\n",
    "\n",
    "# launch client command template\n",
    "# the two clients will use one of the two available GPUs exclusively\n",
    "client_command = \"export CUDA_VISIBLE_DEVICES={client_id} && python rag_federated_learning.py --component client_{client_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd1fbae8-3a0b-45b2-9fe3-09e40aa61900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Started server (PID: 85559)\n"
     ]
    }
   ],
   "source": [
    "# start server process\n",
    "monitor.start_process(\"server\", server_command)\n",
    "\n",
    "# give server time to standup\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07821401-042b-43cf-bfb4-53c0f72364a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Started client_0 (PID: 85585)\n",
      "âœ… Started client_1 (PID: 85588)\n"
     ]
    }
   ],
   "source": [
    "# start client processes\n",
    "monitor.start_process(\n",
    "    name=\"client_0\", command=client_command.format(client_id=\"0\")\n",
    ")\n",
    "monitor.start_process(\n",
    "    name=\"client_1\", command=client_command.format(client_id=\"1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1042b2-e2e1-4d6d-9cb6-c2bcc7e485d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸  PROCESS MONITOR\n",
      "============================================================\n",
      "\n",
      "server ðŸ”´ STOPPED\n",
      "------------------------------\n",
      "[23:36:29] \u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "[23:36:29] \u001b[92mINFO \u001b[0m:\n",
      "[23:36:29] \u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "[23:36:31] \u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "[23:37:20] \u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "[23:37:26] \u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "[23:37:26] \u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "[23:37:41] \u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Run finished 1 round(s) in 72.02s\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      \t\tround 1: 0.41999998688697815\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:\n",
      "\n",
      "client_0 ðŸ”´ STOPPED\n",
      "------------------------------\n",
      "[23:37:09] \n",
      "[23:37:09] \n",
      "[23:37:09] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  2.18s/it]\n",
      "[23:37:09] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.65s/it]\n",
      "[23:37:09] /home/nerdai/Projects/fed-rag/src/fed_rag/fl_tasks/huggingface.py:116: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "[23:37:09] if name in self.task_bundle.model_fields:\n",
      "[23:37:16] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[23:37:40] \u001b[92mINFO \u001b[0m:\n",
      "[23:37:40] \u001b[92mINFO \u001b[0m:      Received: evaluate message 5b749201-b76e-4b83-b8fd-485b59021f3f\n",
      "[23:37:40] \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Received: reconnect message d60bda79-f1e1-4bd1-bb2e-95e8d7496ab6\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
      "[23:37:41] {'train_runtime': 22.963, 'train_samples_per_second': 0.523, 'train_steps_per_second': 0.131, 'train_loss': 2.1859957377115884, 'epoch': 3.0}\n",
      "\n",
      "client_1 ðŸ”´ STOPPED\n",
      "------------------------------\n",
      "[23:37:09] \n",
      "[23:37:09] \n",
      "[23:37:09] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  2.03s/it]\n",
      "[23:37:09] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.49s/it]\n",
      "[23:37:09] /home/nerdai/Projects/fed-rag/src/fed_rag/fl_tasks/huggingface.py:116: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "[23:37:09] if name in self.task_bundle.model_fields:\n",
      "[23:37:17] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[23:37:40] \u001b[92mINFO \u001b[0m:\n",
      "[23:37:40] \u001b[92mINFO \u001b[0m:      Received: evaluate message 0d91065a-9fd8-44e2-b744-c477a3d0cdbc\n",
      "[23:37:40] \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Received: reconnect message 46311e1d-d99c-4a0f-9c3a-2931384263cd\n",
      "[23:37:41] \u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
      "[23:37:41] {'train_runtime': 22.4633, 'train_samples_per_second': 0.534, 'train_steps_per_second': 0.134, 'train_loss': 2.1859957377115884, 'epoch': 3.0}\n",
      "\n",
      "ðŸ”„ Last updated: 23:37:44\n",
      "Press Ctrl+C to stop monitoring\n"
     ]
    }
   ],
   "source": [
    "# this cell will run until completion of the subprocesses or if the kernel is interrupted\n",
    "monitor.monitor_live([\"server\", \"client_0\", \"client_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4a386-6a4d-405d-bdc6-07ad2fee7803",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00a0c987-3e91-46d1-94d8-6708cb1c9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›‘ Stopped server\n",
      "ðŸ›‘ Stopped client_0\n",
      "ðŸ›‘ Stopped client_1\n",
      "ðŸ›‘ All processes stopped\n"
     ]
    }
   ],
   "source": [
    "monitor.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ad215d-5de8-4b75-bba2-46eff8480f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop and remove container\n",
    "container.stop()\n",
    "container.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
