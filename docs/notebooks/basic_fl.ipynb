{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683e31db-0a58-43c7-bb70-efdbe655a735",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VectorInstitute/fed-rag/blob/main/docs/notebooks/rag_benchmarking_hf_mmlu.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "_(NOTE: if running on Colab, you will need to supply a WandB API Key in addition to your HFToken. Also, you'll need to change the runtime to a T4.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b52021-60a9-4de2-b24a-822664beb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc462746-4abe-42e3-a9e9-3914df55a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install docker -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5e360-118b-4535-86ba-8e612f0f0d98",
   "metadata": {},
   "source": [
    "# Basic Federated Fine-tuning of RAG Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193d780-9a08-4fa2-8071-98efa1bb9fc3",
   "metadata": {},
   "source": [
    "## Knowledge Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b7b0a9-505e-4737-be5b-4b8d881eef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 'vectorinstitute/qdrant-atlas-dec-wiki-2021:latest' already exists locally\n",
      "Container started with ID: f8e1721013ed18774e2c89629ac2b3d7f7c3ec6eab6ed48f73b99ee7308a1bc1\n",
      "Container status: running\n",
      "Container logs:\n",
      "Starting Qdrant Atlas Knowledge Store container\n",
      "Running database initialization check...\n",
      "Using tiny sample mode...\n",
      "Creating tiny sample file for testing...\n",
      "Using tiny sample file: tiny-sample.jsonl\n",
      "Verifying sample file creation...\n",
      "âœ… Sample file successfully created at: /app/data/atlas/enwiki-dec2021/tiny-sample.jsonl\n",
      "File details:\n",
      "-rw-r--r-- 1 root root 6785 Jun  8 01:32 /app/data/atlas/enwiki-dec2021/tiny-sample.jsonl\n",
      "File content (first 3 lines):\n",
      "{\"id\": \"140\", \"title\": \"History of marine biology\", \"section\": \"James Cook\", \"text\": \" James Cook is well known for his voyages of exploration for the British Navy in which he mapped out a significant amount of the world's uncharted waters. Cook's explorations took him around the world twice and led to countless descriptions of previously unknown plants and animals. Cook's explorations influenced many others and led to a number of scientists examining marine life more closely. Among those influenced was Charles Darwin who went on to make many contributions of his own. \"}\n",
      "{\"id\": \"141\", \"title\": \"History of marine biology\", \"section\": \"Charles Darwin\", \"text\": \" Charles Darwin, best known for his theory of evolution, made many significant contributions to the early study of marine biology. He spent much of his time from 1831 to 1836 on the voyage of HMS Beagle collecting and studying specimens from a variety of marine organisms. It was also on this expedition where Darwin began to study coral reefs and their formation. He came up with the theory that the overall growth of corals is a balance between the growth of corals upward and the sinking of the sea floor. He then came up with the idea that wherever coral atolls would be found, the central island where the coral had started to grow would be gradually subsiding\"}\n",
      "{\"id\": \"142\", \"title\": \"History of marine biology\", \"section\": \"Charles Wyville Thomson\", \"text\": \" Another influential expedition was the voyage of HMS Challenger from 1872 to 1876, organized and later led by Charles Wyville Thomson. It was the first expedition purely devoted to marine science. The expedition collected and analyzed thousands of marine specimens, laying the foundation for present knowledge about life near the deep-sea floor. The findings from the expedition were a summary of the known natural, physical and chemical ocean science to that time.\"}\n",
      "Directory listing:\n",
      "total 16\n",
      "drwxr-xr-x 2 root root 4096 Jun  8 01:32 .\n",
      "drwxr-xr-x 3 root root 4096 Jun  8 01:32 ..\n",
      "-rw-r--r-- 1 root root 6785 Jun  8 01:32 tiny-sample.jsonl\n",
      "Starting Qdrant service for initialization...\n",
      "Waiting for Qdrant service to be ready...\n",
      "Waiting for Qdrant to start... (Attempt 1/30)\n",
      "           _                 _    \n",
      "  __ _  __| |_ __ __ _ _ __ | |_  \n",
      " / _` |/ _` | '__/ _` | '_ \\| __| \n",
      "| (_| | (_| | | | (_| | | | | |_  \n",
      " \\__, |\\__,_|_|  \\__,_|_| |_|\\__| \n",
      "    |_|                           \n",
      "\n",
      "Version: 1.14.0, build: 3617a011\n",
      "Access web UI at http://localhost:6333/dashboard\n",
      "\n",
      "2025-06-08T01:32:10.258158Z  INFO storage::content_manager::consensus::persistent: Initializing new raft state at ./storage/raft_state.json    \n",
      "2025-06-08T01:32:10.293251Z  INFO qdrant: Distributed mode disabled    \n",
      "2025-06-08T01:32:10.293301Z  INFO qdrant: Telemetry reporting enabled, id: 3960f78d-b4b7-4bbd-9986-374d6a8f2f12    \n",
      "2025-06-08T01:32:10.293373Z  INFO qdrant: Inference service is not configured.    \n",
      "2025-06-08T01:32:10.295740Z  INFO qdrant::actix: TLS disabled for REST API    \n",
      "2025-06-08T01:32:10.295836Z  INFO qdrant::actix: Qdrant HTTP listening on 6333    \n",
      "2025-06-08T01:32:10.295874Z  INFO actix_server::builder: Starting 11 workers\n",
      "2025-06-08T01:32:10.295889Z  INFO actix_server::server: Actix runtime found; starting in Actix runtime\n",
      "2025-06-08T01:32:10.305969Z  INFO qdrant::tonic: Qdrant gRPC listening on 6334    \n",
      "2025-06-08T01:32:10.305994Z  INFO qdrant::tonic: TLS disabled for gRPC API    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import docker\n",
    "import os\n",
    "import time\n",
    "\n",
    "client = docker.from_env()\n",
    "image_name = \"vectorinstitute/qdrant-atlas-dec-wiki-2021:latest\"\n",
    "\n",
    "# first see if we need to pull the docker image\n",
    "try:\n",
    "    client.images.get(image_name)\n",
    "    print(f\"Image '{image_name}' already exists locally\")\n",
    "except docker.errors.ImageNotFound:\n",
    "    print(f\"Image '{image_name}' not found locally. Pulling...\")\n",
    "    # Pull with progress information\n",
    "    for line in client.api.pull(image_name, stream=True, decode=True):\n",
    "        if \"progress\" in line:\n",
    "            print(f\"\\r{line['status']}: {line['progress']}\", end=\"\")\n",
    "        elif \"status\" in line:\n",
    "            print(f\"\\r{line['status']}\", end=\"\")\n",
    "    print(\"\\nPull complete!\")\n",
    "\n",
    "# run the Qdrant container\n",
    "container = client.containers.run(\n",
    "    \"vectorinstitute/qdrant-atlas-dec-wiki-2021:latest\",\n",
    "    detach=True,  # -d flag\n",
    "    name=\"tiny-wiki-dec2021-ks\",  # --name\n",
    "    ports={\"6333/tcp\": 6333, \"6334/tcp\": 6334},  # -p 6333:6333  # -p 6334:6334\n",
    "    volumes={\n",
    "        \"qdrant_data\": {  # -v qdrant_data:/qdrant_storage\n",
    "            \"bind\": \"/qdrant_storage\",\n",
    "            \"mode\": \"rw\",\n",
    "        }\n",
    "    },\n",
    "    environment={\"SAMPLE_SIZE\": \"tiny\"},  # -e SAMPLE_SIZE=tiny\n",
    "    device_requests=[\n",
    "        docker.types.DeviceRequest(\n",
    "            count=-1, capabilities=[[\"gpu\"]]\n",
    "        )  # --gpus all\n",
    "    ],\n",
    "    remove=False,  # Don't auto-remove when stopped\n",
    ")\n",
    "\n",
    "print(f\"Container started with ID: {container.id}\")\n",
    "\n",
    "# wait a moment for the container to initialize\n",
    "time.sleep(3)\n",
    "\n",
    "# Check container status\n",
    "container.reload()  # Refresh container data\n",
    "print(f\"Container status: {container.status}\")\n",
    "print(f\"Container logs:\")\n",
    "print(container.logs().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acda615a-6f88-416b-8ff4-d1f727b4ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container status: running\n"
     ]
    }
   ],
   "source": [
    "print(f\"Container status: {container.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8349a-a992-4bfa-bb5c-78e52362b72e",
   "metadata": {},
   "source": [
    "http://localhost:6333/dashboard#/collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb82562-d609-408b-a342-bd750e01b9a9",
   "metadata": {},
   "source": [
    "### Load the script to build the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1cbc275-f03d-47ae-b00a-5f58d9082b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "GIST_URL = f\"https://gist.githubusercontent.com/nerdai/33e8445ab8b96783f34a7e0464e0b0f0/raw?fresh={int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c97bfc3-be0d-439e-bcbe-1b4517fb3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(GIST_URL)\n",
    "rag_code = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eea9dd8-63ad-4f4c-8ad8-ba7f77b991de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">torch</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">transformers.generation.utils</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">GenerationConfig</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">transformers.utils.quantization_config</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">BitsAndBytesConfig</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">datasets</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Dataset</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">typing</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Literal</span>\n",
       "\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">logging</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">INFO</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">flwr.common.logger</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">log</span>\n",
       "\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">RAGSystem</span><span class=\"p\">,</span> <span class=\"n\">RAGConfig</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.knowledge_stores</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">QdrantKnowledgeStore</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.retrievers</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"p\">(</span>\n",
       "    <span class=\"n\">HFSentenceTransformerRetriever</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.generators</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HFPretrainedModelGenerator</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.fl_tasks.huggingface</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"p\">(</span>\n",
       "    <span class=\"n\">HuggingFaceFlowerClient</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">HuggingFaceFlowerServer</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.data_structures</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">KnowledgeNode</span><span class=\"p\">,</span> <span class=\"n\">NodeType</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.trainers.huggingface.ralt</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HuggingFaceTrainerForRALT</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">fed_rag.trainer_managers.huggingface</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span>\n",
       "\n",
       "<span class=\"n\">GRPC_MAX_MESSAGE_LENGTH</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mi\">512</span> <span class=\"o\">*</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"mf\">3.75</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">PEFT_MODEL_NAME</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;Styxxxx/llama2_7b_lora-quac&quot;</span>\n",
       "<span class=\"n\">BASE_MODEL_NAME</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;meta-llama/Llama-2-7b-hf&quot;</span>\n",
       "<span class=\"n\">TRAIN_DATASET</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_dict</span><span class=\"p\">(</span>\n",
       "    <span class=\"c1\"># examples from Commonsense QA</span>\n",
       "    <span class=\"p\">{</span>\n",
       "        <span class=\"s2\">&quot;query&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;Sammy wanted to go to where the people were.  Where might he go?&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;To locate a choker not located in a jewelry box or boutique where would you go?&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;Google Maps and other highway and street GPS services have replaced what?&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">],</span>\n",
       "        <span class=\"s2\">&quot;response&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;populated areas&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;jewelry store&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;atlas&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">],</span>\n",
       "    <span class=\"p\">}</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"n\">VAL_DATASET</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_dict</span><span class=\"p\">(</span>\n",
       "    <span class=\"p\">{</span>\n",
       "        <span class=\"s2\">&quot;query&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;The fox walked from the city into the forest, what was it looking for?&quot;</span>\n",
       "        <span class=\"p\">],</span>\n",
       "        <span class=\"s2\">&quot;response&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n",
       "            <span class=\"s2\">&quot;natural habitat&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">],</span>\n",
       "    <span class=\"p\">}</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">get_trainer_manager</span><span class=\"p\">(</span><span class=\"n\">server</span><span class=\"p\">:</span> <span class=\"nb\">bool</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># use the knowledge store in image: vectorinstitute/qdrant-atlas-dec-wiki-2021:latest</span>\n",
       "    <span class=\"n\">knowledge_store</span> <span class=\"o\">=</span> <span class=\"n\">QdrantKnowledgeStore</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">collection_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;nthakur.dragon-plus-context-encoder&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"n\">retriever</span> <span class=\"o\">=</span> <span class=\"n\">HFSentenceTransformerRetriever</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">query_model_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;nthakur/dragon-plus-query-encoder&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">context_model_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;nthakur/dragon-plus-context-encoder&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">load_model_at_init</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># LLM generator</span>\n",
       "    <span class=\"n\">generation_cfg</span> <span class=\"o\">=</span> <span class=\"n\">GenerationConfig</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">do_sample</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">eos_token_id</span><span class=\"o\">=</span><span class=\"mi\">151643</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">bos_token_id</span><span class=\"o\">=</span><span class=\"mi\">151643</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">max_new_tokens</span><span class=\"o\">=</span><span class=\"mi\">2048</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">top_p</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mf\">0.6</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">cache_implementation</span><span class=\"o\">=</span><span class=\"s2\">&quot;offloaded&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">stop_strings</span><span class=\"o\">=</span><span class=\"s2\">&quot;&lt;/response&gt;&quot;</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">server</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">load_model_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">&quot;device_map&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;cpu&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;torch_dtype&quot;</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">}</span>\n",
       "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">load_model_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">&quot;device_map&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;auto&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;torch_dtype&quot;</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">}</span>\n",
       "    <span class=\"n\">generator</span> <span class=\"o\">=</span> <span class=\"n\">HFPretrainedModelGenerator</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;Qwen/Qwen2.5-0.5B&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">load_model_at_init</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">load_model_kwargs</span><span class=\"o\">=</span><span class=\"n\">load_model_kwargs</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">generation_config</span><span class=\"o\">=</span><span class=\"n\">generation_cfg</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># assemble rag system</span>\n",
       "    <span class=\"n\">rag_config</span> <span class=\"o\">=</span> <span class=\"n\">RAGConfig</span><span class=\"p\">(</span><span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">rag_system</span> <span class=\"o\">=</span> <span class=\"n\">RAGSystem</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">knowledge_store</span><span class=\"o\">=</span><span class=\"n\">knowledge_store</span><span class=\"p\">,</span>  <span class=\"c1\"># knowledge store loaded from knowledge_store.py</span>\n",
       "        <span class=\"n\">generator</span><span class=\"o\">=</span><span class=\"n\">generator</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">retriever</span><span class=\"o\">=</span><span class=\"n\">retriever</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">rag_config</span><span class=\"o\">=</span><span class=\"n\">rag_config</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    \n",
       "    <span class=\"c1\"># the trainer object</span>\n",
       "    <span class=\"n\">generator_trainer</span> <span class=\"o\">=</span> <span class=\"n\">HuggingFaceTrainerForRALT</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">rag_system</span><span class=\"o\">=</span><span class=\"n\">rag_system</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">train_dataset</span><span class=\"o\">=</span><span class=\"n\">TRAIN_DATASET</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"c1\"># trainer manager object</span>\n",
       "    <span class=\"n\">manager</span> <span class=\"o\">=</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s2\">&quot;generator&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">generator_trainer</span><span class=\"o\">=</span><span class=\"n\">generator_trainer</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">manager</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">build_client</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">train_manager</span><span class=\"p\">:</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">HuggingFaceFlowerClient</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">fl_task</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">get_federated_task</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">model</span>\n",
       "    <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">INFO</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;loaded generator is on: </span><span class=\"si\">{</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">fl_task</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">train_dataset</span><span class=\"o\">=</span><span class=\"n\">TRAIN_DATASET</span><span class=\"p\">,</span> <span class=\"n\">val_dataset</span><span class=\"o\">=</span><span class=\"n\">VAL_DATASET</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">build_server</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">train_manager</span><span class=\"p\">:</span> <span class=\"n\">HuggingFaceRAGTrainerManager</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">HuggingFaceFlowerServer</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">fl_task</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">get_federated_task</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">train_manager</span><span class=\"o\">.</span><span class=\"n\">model</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">fl_task</span><span class=\"o\">.</span><span class=\"n\">server</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">main</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">component</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s2\">&quot;server&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client_0&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client_1&quot;</span><span class=\"p\">],</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "    <span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">flwr</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">fl</span>\n",
       "\n",
       "    <span class=\"k\">if</span> <span class=\"n\">component</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;server&quot;</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">manager</span> <span class=\"o\">=</span> <span class=\"n\">get_trainer_manager</span><span class=\"p\">(</span><span class=\"n\">server</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">server</span> <span class=\"o\">=</span> <span class=\"n\">build_server</span><span class=\"p\">(</span><span class=\"n\">manager</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">fl</span><span class=\"o\">.</span><span class=\"n\">server</span><span class=\"o\">.</span><span class=\"n\">start_server</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">server</span><span class=\"o\">=</span><span class=\"n\">server</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">server_address</span><span class=\"o\">=</span><span class=\"s2\">&quot;[::]:8080&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">grpc_max_message_length</span><span class=\"o\">=</span><span class=\"n\">GRPC_MAX_MESSAGE_LENGTH</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "    <span class=\"k\">elif</span> <span class=\"n\">component</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s2\">&quot;client_0&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client_1&quot;</span><span class=\"p\">]:</span>\n",
       "        <span class=\"n\">manager</span> <span class=\"o\">=</span> <span class=\"n\">get_trainer_manager</span><span class=\"p\">(</span><span class=\"n\">server</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">build_client</span><span class=\"p\">(</span><span class=\"n\">manager</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">fl</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">start_client</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">client</span><span class=\"o\">=</span><span class=\"n\">client</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">server_address</span><span class=\"o\">=</span><span class=\"s2\">&quot;[::]:8080&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">grpc_max_message_length</span><span class=\"o\">=</span><span class=\"n\">GRPC_MAX_MESSAGE_LENGTH</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span><span class=\"s2\">&quot;Unrecognized component.&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">fire</span>\n",
       "\n",
       "    <span class=\"n\">fire</span><span class=\"o\">.</span><span class=\"n\">Fire</span><span class=\"p\">(</span><span class=\"n\">main</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{torch}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{transformers}\\PY{n+nn}{.}\\PY{n+nn}{generation}\\PY{n+nn}{.}\\PY{n+nn}{utils}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{GenerationConfig}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{transformers}\\PY{n+nn}{.}\\PY{n+nn}{utils}\\PY{n+nn}{.}\\PY{n+nn}{quantization\\PYZus{}config}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{BitsAndBytesConfig}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{datasets}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{Dataset}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{typing}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{Literal}\n",
       "\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{logging}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{INFO}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{flwr}\\PY{n+nn}{.}\\PY{n+nn}{common}\\PY{n+nn}{.}\\PY{n+nn}{logger}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{log}\n",
       "\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{RAGSystem}\\PY{p}{,} \\PY{n}{RAGConfig}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{knowledge\\PYZus{}stores}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{QdrantKnowledgeStore}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{retrievers}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{p}{(}\n",
       "    \\PY{n}{HFSentenceTransformerRetriever}\\PY{p}{,}\n",
       "\\PY{p}{)}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{generators}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HFPretrainedModelGenerator}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{fl\\PYZus{}tasks}\\PY{n+nn}{.}\\PY{n+nn}{huggingface}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{p}{(}\n",
       "    \\PY{n}{HuggingFaceFlowerClient}\\PY{p}{,}\n",
       "    \\PY{n}{HuggingFaceFlowerServer}\\PY{p}{,}\n",
       "\\PY{p}{)}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{data\\PYZus{}structures}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{KnowledgeNode}\\PY{p}{,} \\PY{n}{NodeType}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{trainers}\\PY{n+nn}{.}\\PY{n+nn}{huggingface}\\PY{n+nn}{.}\\PY{n+nn}{ralt}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HuggingFaceTrainerForRALT}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{fed\\PYZus{}rag}\\PY{n+nn}{.}\\PY{n+nn}{trainer\\PYZus{}managers}\\PY{n+nn}{.}\\PY{n+nn}{huggingface}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HuggingFaceRAGTrainerManager}\n",
       "\n",
       "\\PY{n}{GRPC\\PYZus{}MAX\\PYZus{}MESSAGE\\PYZus{}LENGTH} \\PY{o}{=} \\PY{n+nb}{int}\\PY{p}{(}\\PY{l+m+mi}{512} \\PY{o}{*} \\PY{l+m+mi}{1024} \\PY{o}{*} \\PY{l+m+mi}{1024} \\PY{o}{*} \\PY{l+m+mf}{3.75}\\PY{p}{)}\n",
       "\\PY{n}{PEFT\\PYZus{}MODEL\\PYZus{}NAME} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Styxxxx/llama2\\PYZus{}7b\\PYZus{}lora\\PYZhy{}quac}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "\\PY{n}{BASE\\PYZus{}MODEL\\PYZus{}NAME} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{meta\\PYZhy{}llama/Llama\\PYZhy{}2\\PYZhy{}7b\\PYZhy{}hf}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "\\PY{n}{TRAIN\\PYZus{}DATASET} \\PY{o}{=} \\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}dict}\\PY{p}{(}\n",
       "    \\PY{c+c1}{\\PYZsh{} examples from Commonsense QA}\n",
       "    \\PY{p}{\\PYZob{}}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{query}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Sammy wanted to go to where the people were.  Where might he go?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{To locate a choker not located in a jewelry box or boutique where would you go?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Google Maps and other highway and street GPS services have replaced what?}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{response}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{populated areas}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{jewelry store}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{atlas}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "    \\PY{p}{\\PYZcb{}}\n",
       "\\PY{p}{)}\n",
       "\\PY{n}{VAL\\PYZus{}DATASET} \\PY{o}{=} \\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}dict}\\PY{p}{(}\n",
       "    \\PY{p}{\\PYZob{}}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{query}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{The fox walked from the city into the forest, what was it looking for?}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{response}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{[}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{natural habitat}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{]}\\PY{p}{,}\n",
       "    \\PY{p}{\\PYZcb{}}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{get\\PYZus{}trainer\\PYZus{}manager}\\PY{p}{(}\\PY{n}{server}\\PY{p}{:} \\PY{n+nb}{bool}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} use the knowledge store in image: vectorinstitute/qdrant\\PYZhy{}atlas\\PYZhy{}dec\\PYZhy{}wiki\\PYZhy{}2021:latest}\n",
       "    \\PY{n}{knowledge\\PYZus{}store} \\PY{o}{=} \\PY{n}{QdrantKnowledgeStore}\\PY{p}{(}\n",
       "        \\PY{n}{collection\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{nthakur.dragon\\PYZhy{}plus\\PYZhy{}context\\PYZhy{}encoder}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{timeout}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{n}{retriever} \\PY{o}{=} \\PY{n}{HFSentenceTransformerRetriever}\\PY{p}{(}\n",
       "        \\PY{n}{query\\PYZus{}model\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{nthakur/dragon\\PYZhy{}plus\\PYZhy{}query\\PYZhy{}encoder}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{context\\PYZus{}model\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{nthakur/dragon\\PYZhy{}plus\\PYZhy{}context\\PYZhy{}encoder}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}at\\PYZus{}init}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} LLM generator}\n",
       "    \\PY{n}{generation\\PYZus{}cfg} \\PY{o}{=} \\PY{n}{GenerationConfig}\\PY{p}{(}\n",
       "        \\PY{n}{do\\PYZus{}sample}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,}\n",
       "        \\PY{n}{eos\\PYZus{}token\\PYZus{}id}\\PY{o}{=}\\PY{l+m+mi}{151643}\\PY{p}{,}\n",
       "        \\PY{n}{bos\\PYZus{}token\\PYZus{}id}\\PY{o}{=}\\PY{l+m+mi}{151643}\\PY{p}{,}\n",
       "        \\PY{n}{max\\PYZus{}new\\PYZus{}tokens}\\PY{o}{=}\\PY{l+m+mi}{2048}\\PY{p}{,}\n",
       "        \\PY{n}{top\\PYZus{}p}\\PY{o}{=}\\PY{l+m+mf}{0.9}\\PY{p}{,}\n",
       "        \\PY{n}{temperature}\\PY{o}{=}\\PY{l+m+mf}{0.6}\\PY{p}{,}\n",
       "        \\PY{n}{cache\\PYZus{}implementation}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{offloaded}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{stop\\PYZus{}strings}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZlt{}/response\\PYZgt{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{k}{if} \\PY{n}{server}\\PY{p}{:}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}kwargs} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{device\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{cpu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{torch\\PYZus{}dtype}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{float16}\\PY{p}{\\PYZcb{}}\n",
       "    \\PY{k}{else}\\PY{p}{:}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}kwargs} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{device\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{auto}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{torch\\PYZus{}dtype}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{float16}\\PY{p}{\\PYZcb{}}\n",
       "    \\PY{n}{generator} \\PY{o}{=} \\PY{n}{HFPretrainedModelGenerator}\\PY{p}{(}\n",
       "        \\PY{n}{model\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Qwen/Qwen2.5\\PYZhy{}0.5B}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}at\\PYZus{}init}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{,}\n",
       "        \\PY{n}{load\\PYZus{}model\\PYZus{}kwargs}\\PY{o}{=}\\PY{n}{load\\PYZus{}model\\PYZus{}kwargs}\\PY{p}{,}\n",
       "        \\PY{n}{generation\\PYZus{}config}\\PY{o}{=}\\PY{n}{generation\\PYZus{}cfg}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} assemble rag system}\n",
       "    \\PY{n}{rag\\PYZus{}config} \\PY{o}{=} \\PY{n}{RAGConfig}\\PY{p}{(}\\PY{n}{top\\PYZus{}k}\\PY{o}{=}\\PY{l+m+mi}{2}\\PY{p}{)}\n",
       "    \\PY{n}{rag\\PYZus{}system} \\PY{o}{=} \\PY{n}{RAGSystem}\\PY{p}{(}\n",
       "        \\PY{n}{knowledge\\PYZus{}store}\\PY{o}{=}\\PY{n}{knowledge\\PYZus{}store}\\PY{p}{,}  \\PY{c+c1}{\\PYZsh{} knowledge store loaded from knowledge\\PYZus{}store.py}\n",
       "        \\PY{n}{generator}\\PY{o}{=}\\PY{n}{generator}\\PY{p}{,}\n",
       "        \\PY{n}{retriever}\\PY{o}{=}\\PY{n}{retriever}\\PY{p}{,}\n",
       "        \\PY{n}{rag\\PYZus{}config}\\PY{o}{=}\\PY{n}{rag\\PYZus{}config}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} the trainer object}\n",
       "    \\PY{n}{generator\\PYZus{}trainer} \\PY{o}{=} \\PY{n}{HuggingFaceTrainerForRALT}\\PY{p}{(}\n",
       "        \\PY{n}{rag\\PYZus{}system}\\PY{o}{=}\\PY{n}{rag\\PYZus{}system}\\PY{p}{,}\n",
       "        \\PY{n}{train\\PYZus{}dataset}\\PY{o}{=}\\PY{n}{TRAIN\\PYZus{}DATASET}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{c+c1}{\\PYZsh{} trainer manager object}\n",
       "    \\PY{n}{manager} \\PY{o}{=} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{(}\n",
       "        \\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{generator}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{generator\\PYZus{}trainer}\\PY{o}{=}\\PY{n}{generator\\PYZus{}trainer}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{manager}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{build\\PYZus{}client}\\PY{p}{(}\n",
       "    \\PY{n}{train\\PYZus{}manager}\\PY{p}{:} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{HuggingFaceFlowerClient}\\PY{p}{:}\n",
       "    \\PY{n}{fl\\PYZus{}task} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{get\\PYZus{}federated\\PYZus{}task}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{model} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{model}\n",
       "    \\PY{n}{log}\\PY{p}{(}\\PY{n}{INFO}\\PY{p}{,} \\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{loaded generator is on: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{model}\\PY{o}{.}\\PY{n}{device}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{fl\\PYZus{}task}\\PY{o}{.}\\PY{n}{client}\\PY{p}{(}\n",
       "        \\PY{n}{model}\\PY{o}{=}\\PY{n}{model}\\PY{p}{,} \\PY{n}{train\\PYZus{}dataset}\\PY{o}{=}\\PY{n}{TRAIN\\PYZus{}DATASET}\\PY{p}{,} \\PY{n}{val\\PYZus{}dataset}\\PY{o}{=}\\PY{n}{VAL\\PYZus{}DATASET}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{build\\PYZus{}server}\\PY{p}{(}\n",
       "    \\PY{n}{train\\PYZus{}manager}\\PY{p}{:} \\PY{n}{HuggingFaceRAGTrainerManager}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{HuggingFaceFlowerServer}\\PY{p}{:}\n",
       "    \\PY{n}{fl\\PYZus{}task} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{get\\PYZus{}federated\\PYZus{}task}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{model} \\PY{o}{=} \\PY{n}{train\\PYZus{}manager}\\PY{o}{.}\\PY{n}{model}\n",
       "    \\PY{k}{return} \\PY{n}{fl\\PYZus{}task}\\PY{o}{.}\\PY{n}{server}\\PY{p}{(}\\PY{n}{model}\\PY{o}{=}\\PY{n}{model}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{main}\\PY{p}{(}\n",
       "    \\PY{n}{component}\\PY{p}{:} \\PY{n}{Literal}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{server}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{k+kc}{None}\\PY{p}{:}\n",
       "    \\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{flwr}\\PY{+w}{ }\\PY{k}{as}\\PY{+w}{ }\\PY{n+nn}{fl}\n",
       "\n",
       "    \\PY{k}{if} \\PY{n}{component} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{server}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "        \\PY{n}{manager} \\PY{o}{=} \\PY{n}{get\\PYZus{}trainer\\PYZus{}manager}\\PY{p}{(}\\PY{n}{server}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "        \\PY{n}{server} \\PY{o}{=} \\PY{n}{build\\PYZus{}server}\\PY{p}{(}\\PY{n}{manager}\\PY{p}{)}\n",
       "        \\PY{n}{fl}\\PY{o}{.}\\PY{n}{server}\\PY{o}{.}\\PY{n}{start\\PYZus{}server}\\PY{p}{(}\n",
       "            \\PY{n}{server}\\PY{o}{=}\\PY{n}{server}\\PY{p}{,}\n",
       "            \\PY{n}{server\\PYZus{}address}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{[::]:8080}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{grpc\\PYZus{}max\\PYZus{}message\\PYZus{}length}\\PY{o}{=}\\PY{n}{GRPC\\PYZus{}MAX\\PYZus{}MESSAGE\\PYZus{}LENGTH}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "    \\PY{k}{elif} \\PY{n}{component} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{client\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "        \\PY{n}{manager} \\PY{o}{=} \\PY{n}{get\\PYZus{}trainer\\PYZus{}manager}\\PY{p}{(}\\PY{n}{server}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
       "        \\PY{n}{client} \\PY{o}{=} \\PY{n}{build\\PYZus{}client}\\PY{p}{(}\\PY{n}{manager}\\PY{p}{)}\n",
       "        \\PY{n}{fl}\\PY{o}{.}\\PY{n}{client}\\PY{o}{.}\\PY{n}{start\\PYZus{}client}\\PY{p}{(}\n",
       "            \\PY{n}{client}\\PY{o}{=}\\PY{n}{client}\\PY{p}{,}\n",
       "            \\PY{n}{server\\PYZus{}address}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{[::]:8080}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{grpc\\PYZus{}max\\PYZus{}message\\PYZus{}length}\\PY{o}{=}\\PY{n}{GRPC\\PYZus{}MAX\\PYZus{}MESSAGE\\PYZus{}LENGTH}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "    \\PY{k}{else}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{ValueError}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Unrecognized component.}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{fire}\n",
       "\n",
       "    \\PY{n}{fire}\\PY{o}{.}\\PY{n}{Fire}\\PY{p}{(}\\PY{n}{main}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch\n",
       "from transformers.generation.utils import GenerationConfig\n",
       "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
       "from datasets import Dataset\n",
       "from typing import Literal\n",
       "\n",
       "from logging import INFO\n",
       "from flwr.common.logger import log\n",
       "\n",
       "from fed_rag import RAGSystem, RAGConfig\n",
       "from fed_rag.knowledge_stores import QdrantKnowledgeStore\n",
       "from fed_rag.retrievers import (\n",
       "    HFSentenceTransformerRetriever,\n",
       ")\n",
       "from fed_rag.generators import HFPretrainedModelGenerator\n",
       "from fed_rag.fl_tasks.huggingface import (\n",
       "    HuggingFaceFlowerClient,\n",
       "    HuggingFaceFlowerServer,\n",
       ")\n",
       "from fed_rag.data_structures import KnowledgeNode, NodeType\n",
       "from fed_rag.trainers.huggingface.ralt import HuggingFaceTrainerForRALT\n",
       "from fed_rag.trainer_managers.huggingface import HuggingFaceRAGTrainerManager\n",
       "\n",
       "GRPC_MAX_MESSAGE_LENGTH = int(512 * 1024 * 1024 * 3.75)\n",
       "PEFT_MODEL_NAME = \"Styxxxx/llama2_7b_lora-quac\"\n",
       "BASE_MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
       "TRAIN_DATASET = Dataset.from_dict(\n",
       "    # examples from Commonsense QA\n",
       "    {\n",
       "        \"query\": [\n",
       "            \"The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\",\n",
       "            \"Sammy wanted to go to where the people were.  Where might he go?\",\n",
       "            \"To locate a choker not located in a jewelry box or boutique where would you go?\",\n",
       "            \"Google Maps and other highway and street GPS services have replaced what?\",\n",
       "        ],\n",
       "        \"response\": [\n",
       "            \"ignore\",\n",
       "            \"populated areas\",\n",
       "            \"jewelry store\",\n",
       "            \"atlas\",\n",
       "        ],\n",
       "    }\n",
       ")\n",
       "VAL_DATASET = Dataset.from_dict(\n",
       "    {\n",
       "        \"query\": [\n",
       "            \"The fox walked from the city into the forest, what was it looking for?\"\n",
       "        ],\n",
       "        \"response\": [\n",
       "            \"natural habitat\",\n",
       "        ],\n",
       "    }\n",
       ")\n",
       "\n",
       "\n",
       "def get_trainer_manager(server: bool) -> HuggingFaceRAGTrainerManager:\n",
       "    # use the knowledge store in image: vectorinstitute/qdrant-atlas-dec-wiki-2021:latest\n",
       "    knowledge_store = QdrantKnowledgeStore(\n",
       "        collection_name=\"nthakur.dragon-plus-context-encoder\",\n",
       "        timeout=10,\n",
       "    )\n",
       "    retriever = HFSentenceTransformerRetriever(\n",
       "        query_model_name=\"nthakur/dragon-plus-query-encoder\",\n",
       "        context_model_name=\"nthakur/dragon-plus-context-encoder\",\n",
       "        load_model_at_init=False,\n",
       "    )\n",
       "\n",
       "    # LLM generator\n",
       "    generation_cfg = GenerationConfig(\n",
       "        do_sample=True,\n",
       "        eos_token_id=151643,\n",
       "        bos_token_id=151643,\n",
       "        max_new_tokens=2048,\n",
       "        top_p=0.9,\n",
       "        temperature=0.6,\n",
       "        cache_implementation=\"offloaded\",\n",
       "        stop_strings=\"</response>\",\n",
       "    )\n",
       "    if server:\n",
       "        load_model_kwargs = {\"device_map\": \"cpu\", \"torch_dtype\": torch.float16}\n",
       "    else:\n",
       "        load_model_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": torch.float16}\n",
       "    generator = HFPretrainedModelGenerator(\n",
       "        model_name=\"Qwen/Qwen2.5-0.5B\",\n",
       "        load_model_at_init=False,\n",
       "        load_model_kwargs=load_model_kwargs,\n",
       "        generation_config=generation_cfg,\n",
       "    )\n",
       "\n",
       "    # assemble rag system\n",
       "    rag_config = RAGConfig(top_k=2)\n",
       "    rag_system = RAGSystem(\n",
       "        knowledge_store=knowledge_store,  # knowledge store loaded from knowledge_store.py\n",
       "        generator=generator,\n",
       "        retriever=retriever,\n",
       "        rag_config=rag_config,\n",
       "    )\n",
       "    \n",
       "    # the trainer object\n",
       "    generator_trainer = HuggingFaceTrainerForRALT(\n",
       "        rag_system=rag_system,\n",
       "        train_dataset=TRAIN_DATASET,\n",
       "    )\n",
       "    # trainer manager object\n",
       "    manager = HuggingFaceRAGTrainerManager(\n",
       "        mode=\"generator\",\n",
       "        generator_trainer=generator_trainer,\n",
       "    )\n",
       "    return manager\n",
       "\n",
       "\n",
       "def build_client(\n",
       "    train_manager: HuggingFaceRAGTrainerManager,\n",
       ") -> HuggingFaceFlowerClient:\n",
       "    fl_task = train_manager.get_federated_task()\n",
       "    model = train_manager.model\n",
       "    log(INFO, f\"loaded generator is on: {model.device}\")\n",
       "    return fl_task.client(\n",
       "        model=model, train_dataset=TRAIN_DATASET, val_dataset=VAL_DATASET\n",
       "    )\n",
       "\n",
       "\n",
       "def build_server(\n",
       "    train_manager: HuggingFaceRAGTrainerManager,\n",
       ") -> HuggingFaceFlowerServer:\n",
       "    fl_task = train_manager.get_federated_task()\n",
       "    model = train_manager.model\n",
       "    return fl_task.server(model=model)\n",
       "\n",
       "\n",
       "def main(\n",
       "    component: Literal[\"server\", \"client_0\", \"client_1\"],\n",
       ") -> None:\n",
       "    import flwr as fl\n",
       "\n",
       "    if component == \"server\":\n",
       "        manager = get_trainer_manager(server=True)\n",
       "        server = build_server(manager)\n",
       "        fl.server.start_server(\n",
       "            server=server,\n",
       "            server_address=\"[::]:8080\",\n",
       "            grpc_max_message_length=GRPC_MAX_MESSAGE_LENGTH,\n",
       "        )\n",
       "    elif component in [\"client_0\", \"client_1\"]:\n",
       "        manager = get_trainer_manager(server=False)\n",
       "        client = build_client(manager)\n",
       "        fl.client.start_client(\n",
       "            client=client,\n",
       "            server_address=\"[::]:8080\",\n",
       "            grpc_max_message_length=GRPC_MAX_MESSAGE_LENGTH,\n",
       "        )\n",
       "    else:\n",
       "        raise ValueError(\"Unrecognized component.\")\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    import fire\n",
       "\n",
       "    fire.Fire(main)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Code, display\n",
    "\n",
    "display(Code(rag_code, language=\"python\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbcff1-96f1-4664-9da6-b84aa43d6347",
   "metadata": {},
   "source": [
    "### Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f36001d-4cbf-42c8-a7dd-22eea3d3d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a21c091c-094b-4ac9-9da4-443edec578ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write gist to script\n",
    "with open(\"rag_federated_learning.py\", \"w\") as f:\n",
    "    f.write(rag_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2392c8-2002-41ac-a2bb-c0638e0ef361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rag.utils.notebook import ProcessMonitor\n",
    "\n",
    "monitor = ProcessMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea1773a-6c61-4170-839f-61334f6657fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_command = \"python rag_federated_learning.py --component server\"\n",
    "client_command = \"export CUDA_VISIBLE_DEVICES={client_id} && python rag_federated_learning.py --component client_{client_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1fbae8-3a0b-45b2-9fe3-09e40aa61900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Started server (PID: 66185)\n"
     ]
    }
   ],
   "source": [
    "# start server process\n",
    "monitor.start_process(\"server\", server_command)\n",
    "\n",
    "# give server time to standup\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07821401-042b-43cf-bfb4-53c0f72364a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Started client_0 (PID: 66214)\n",
      "âœ… Started client_1 (PID: 66217)\n"
     ]
    }
   ],
   "source": [
    "# start client processes\n",
    "monitor.start_process(\"client_0\", client_command.format(client_id=\"0\"))\n",
    "monitor.start_process(\"client_1\", client_command.format(client_id=\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1042b2-e2e1-4d6d-9cb6-c2bcc7e485d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸  PROCESS MONITOR\n",
      "============================================================\n",
      "\n",
      "server ðŸ”´ STOPPED\n",
      "------------------------------\n",
      "[21:33:11] \u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "[21:33:11] \u001b[92mINFO \u001b[0m:\n",
      "[21:33:11] \u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "[21:33:13] \u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "[21:34:04] \u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "[21:34:09] \u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "[21:34:09] \u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "[21:34:24] \u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Run finished 1 round(s) in 73.33s\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      \t\tround 1: 0.41999998688697815\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:\n",
      "\n",
      "client_0 ðŸ”´ STOPPED\n",
      "------------------------------\n",
      "[21:33:55] \n",
      "[21:33:55] \n",
      "[21:33:55] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  2.29s/it]\n",
      "[21:33:55] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.94s/it]\n",
      "[21:33:55] /home/nerdai/Projects/fed-rag/src/fed_rag/fl_tasks/huggingface.py:116: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "[21:33:55] if name in self.task_bundle.model_fields:\n",
      "[21:34:02] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[21:34:23] \u001b[92mINFO \u001b[0m:\n",
      "[21:34:23] \u001b[92mINFO \u001b[0m:      Received: evaluate message bf222beb-a913-4b3c-91cd-43c6500ff500\n",
      "[21:34:23] \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Received: reconnect message 28449359-c213-42c2-aeb3-02b0151a72e3\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
      "[21:34:25] {'train_runtime': 26.8279, 'train_samples_per_second': 0.447, 'train_steps_per_second': 0.112, 'train_loss': 2.1859957377115884, 'epoch': 3.0}\n",
      "\n",
      "client_1 ðŸ”´ STOPPED\n",
      "------------------------------\n",
      "[21:33:46] \n",
      "[21:33:46] \n",
      "[21:33:46] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:17<00:00,  1.95s/it]\n",
      "[21:33:46] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:17<00:00,  5.87s/it]\n",
      "[21:33:46] /home/nerdai/Projects/fed-rag/src/fed_rag/fl_tasks/huggingface.py:116: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "[21:33:46] if name in self.task_bundle.model_fields:\n",
      "[21:33:53] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[21:34:23] \u001b[92mINFO \u001b[0m:\n",
      "[21:34:23] \u001b[92mINFO \u001b[0m:      Received: evaluate message 240b1ca6-fdda-48d4-bca5-3ab70c248d0b\n",
      "[21:34:23] \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Sent reply\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Received: reconnect message 024651c9-3d24-4e33-900a-a4a3cd4167b3\n",
      "[21:34:24] \u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
      "[21:34:25] {'train_runtime': 17.6123, 'train_samples_per_second': 0.681, 'train_steps_per_second': 0.17, 'train_loss': 2.1859957377115884, 'epoch': 3.0}\n",
      "\n",
      "ðŸ”„ Last updated: 21:34:27\n",
      "Press Ctrl+C to stop monitoring\n"
     ]
    }
   ],
   "source": [
    "monitor.monitor_live([\"server\", \"client_0\", \"client_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a0c987-3e91-46d1-94d8-6708cb1c9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›‘ Stopped server\n",
      "ðŸ›‘ Stopped client_0\n",
      "ðŸ›‘ Stopped client_1\n",
      "ðŸ›‘ All processes stopped\n"
     ]
    }
   ],
   "source": [
    "monitor.stop_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4a386-6a4d-405d-bdc6-07ad2fee7803",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ad215d-5de8-4b75-bba2-46eff8480f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop and remove container\n",
    "container.stop()\n",
    "container.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
