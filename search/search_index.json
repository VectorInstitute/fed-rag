{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"references/","title":"API references","text":""},{"location":"references/#src.fed_rag.base","title":"<code>base</code>","text":""},{"location":"references/#src.fed_rag.base.BaseFLTask","title":"<code>BaseFLTask</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>class BaseFLTask(BaseModel, ABC):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @property\n    @abstractmethod\n    def training_loop(self) -&gt; Callable:\n        ...\n\n    @classmethod\n    @abstractmethod\n    def from_configs(\n        cls, trainer_cfg: BaseFLTaskConfig, tester_cfg: Any\n    ) -&gt; Self:\n        ...\n\n    @classmethod\n    @abstractmethod\n    def from_trainer_and_tester(\n        cls, trainer: Callable, tester: Callable\n    ) -&gt; Self:\n        try:\n            trainer_cfg = getattr(trainer, \"__fl_task_trainer_config\")\n        except AttributeError:\n            msg = (\n                \"`__fl_task_trainer_config` has not been set on training loop. Make \"\n                \"sure to decorate your training loop with the appropriate \"\n                \"decorator.\"\n            )\n            raise MissingFLTaskConfig(msg)\n\n        try:\n            tester_cfg = getattr(tester, \"__fl_task_tester_config\")\n        except AttributeError:\n            msg = (\n                \"`__fl_task_tester_config` has not been set on tester callable. Make \"\n                \"sure to decorate your tester with the appropriate decorator.\"\n            )\n            raise MissingFLTaskConfig(msg)\n        return cls.from_configs(trainer_cfg, tester_cfg)\n\n    @abstractmethod\n    def simulate(self, num_clients: int, **kwargs: Any) -&gt; Any:\n        \"\"\"Simulate the FL task.\n\n        Either use flwr's simulation tools, or create our own here.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def server(self, **kwargs: Any) -&gt; Server:\n        \"\"\"Create a flwr.Server object.\"\"\"\n        ...\n\n    @abstractmethod\n    def client(self, **kwargs: Any) -&gt; Client:\n        \"\"\"Create a flwr.Client object.\"\"\"\n        ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.BaseFLTask.client","title":"<code>client(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Create a flwr.Client object.</p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>@abstractmethod\ndef client(self, **kwargs: Any) -&gt; Client:\n    \"\"\"Create a flwr.Client object.\"\"\"\n    ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.BaseFLTask.server","title":"<code>server(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Create a flwr.Server object.</p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>@abstractmethod\ndef server(self, **kwargs: Any) -&gt; Server:\n    \"\"\"Create a flwr.Server object.\"\"\"\n    ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.BaseFLTask.simulate","title":"<code>simulate(num_clients, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Simulate the FL task.</p> <p>Either use flwr's simulation tools, or create our own here.</p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>@abstractmethod\ndef simulate(self, num_clients: int, **kwargs: Any) -&gt; Any:\n    \"\"\"Simulate the FL task.\n\n    Either use flwr's simulation tools, or create our own here.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.BaseTrainerConfig","title":"<code>BaseTrainerConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/fed_rag/base/trainer_config.py</code> <pre><code>class BaseTrainerConfig(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    net: Any\n    train_data: Any\n    val_data: Any\n    _extra_train_kwargs: Dict[str, Any] = PrivateAttr(\n        default_factory=dict\n    )  # additional kwargs\n\n    def __init__(self, **params: Any):\n        \"\"\"__init__.\n\n        Sets specified fields and private attrs of the TrainerConfig and then\n        stores any additional passed params in _extra_train_kwargs.\n        \"\"\"\n        fields = {}\n        private_attrs = {}\n        extra_train_kwargs = {}\n        for k, v in params.items():\n            if k in self.model_fields:\n                fields[k] = v\n            elif k in self.__private_attributes__:\n                private_attrs[k] = v\n            else:\n                extra_train_kwargs[k] = v\n        super().__init__(**fields)\n        for private_attr, value in private_attrs.items():\n            super().__setattr__(private_attr, value)\n        if extra_train_kwargs:\n            self._extra_train_kwargs.update(extra_train_kwargs)\n\n    @model_serializer(mode=\"wrap\")\n    def custom_model_dump(self, handler: Any) -&gt; Dict[str, Any]:\n        data = handler(self)\n        data = cast(Dict[str, Any], data)\n        # include _extra_train_kwargs in serialization\n        if self._extra_train_kwargs:\n            data[\"_extra_train_kwargs\"] = self._extra_train_kwargs\n        return data  # type: ignore[no-any-return]\n\n    def __getattr__(self, __name: str) -&gt; Any:\n        if (\n            __name in self.__private_attributes__\n            or __name in self.model_fields\n        ):\n            return super().__getattr__(__name)  # type: ignore\n        else:\n            try:\n                return self._data[__name]\n            except KeyError:\n                raise AttributeError(\n                    f\"'{self.__class__.__name__}' object has no attribute '{__name}'\"\n                )\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        if name in self.__private_attributes__ or name in self.model_fields:\n            super().__setattr__(name, value)\n        else:\n            self._extra_train_kwargs.__setitem__(name, value)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        return self._extra_train_kwargs[key]\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        self._extra_train_kwargs[key] = value\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        return self._extra_train_kwargs.get(key, default)\n\n    def __contains__(self, key: str) -&gt; bool:\n        return key in self._extra_train_kwargs\n</code></pre>"},{"location":"references/#src.fed_rag.base.BaseTrainerConfig.__init__","title":"<code>__init__(**params)</code>","text":"<p>init.</p> <p>Sets specified fields and private attrs of the TrainerConfig and then stores any additional passed params in _extra_train_kwargs.</p> Source code in <code>src/fed_rag/base/trainer_config.py</code> <pre><code>def __init__(self, **params: Any):\n    \"\"\"__init__.\n\n    Sets specified fields and private attrs of the TrainerConfig and then\n    stores any additional passed params in _extra_train_kwargs.\n    \"\"\"\n    fields = {}\n    private_attrs = {}\n    extra_train_kwargs = {}\n    for k, v in params.items():\n        if k in self.model_fields:\n            fields[k] = v\n        elif k in self.__private_attributes__:\n            private_attrs[k] = v\n        else:\n            extra_train_kwargs[k] = v\n    super().__init__(**fields)\n    for private_attr, value in private_attrs.items():\n        super().__setattr__(private_attr, value)\n    if extra_train_kwargs:\n        self._extra_train_kwargs.update(extra_train_kwargs)\n</code></pre>"},{"location":"references/#src.fed_rag.base.fl_task","title":"<code>fl_task</code>","text":"<p>Base FL Task</p>"},{"location":"references/#src.fed_rag.base.fl_task.BaseFLTask","title":"<code>BaseFLTask</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>class BaseFLTask(BaseModel, ABC):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @property\n    @abstractmethod\n    def training_loop(self) -&gt; Callable:\n        ...\n\n    @classmethod\n    @abstractmethod\n    def from_configs(\n        cls, trainer_cfg: BaseFLTaskConfig, tester_cfg: Any\n    ) -&gt; Self:\n        ...\n\n    @classmethod\n    @abstractmethod\n    def from_trainer_and_tester(\n        cls, trainer: Callable, tester: Callable\n    ) -&gt; Self:\n        try:\n            trainer_cfg = getattr(trainer, \"__fl_task_trainer_config\")\n        except AttributeError:\n            msg = (\n                \"`__fl_task_trainer_config` has not been set on training loop. Make \"\n                \"sure to decorate your training loop with the appropriate \"\n                \"decorator.\"\n            )\n            raise MissingFLTaskConfig(msg)\n\n        try:\n            tester_cfg = getattr(tester, \"__fl_task_tester_config\")\n        except AttributeError:\n            msg = (\n                \"`__fl_task_tester_config` has not been set on tester callable. Make \"\n                \"sure to decorate your tester with the appropriate decorator.\"\n            )\n            raise MissingFLTaskConfig(msg)\n        return cls.from_configs(trainer_cfg, tester_cfg)\n\n    @abstractmethod\n    def simulate(self, num_clients: int, **kwargs: Any) -&gt; Any:\n        \"\"\"Simulate the FL task.\n\n        Either use flwr's simulation tools, or create our own here.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def server(self, **kwargs: Any) -&gt; Server:\n        \"\"\"Create a flwr.Server object.\"\"\"\n        ...\n\n    @abstractmethod\n    def client(self, **kwargs: Any) -&gt; Client:\n        \"\"\"Create a flwr.Client object.\"\"\"\n        ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.fl_task.BaseFLTask.client","title":"<code>client(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Create a flwr.Client object.</p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>@abstractmethod\ndef client(self, **kwargs: Any) -&gt; Client:\n    \"\"\"Create a flwr.Client object.\"\"\"\n    ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.fl_task.BaseFLTask.server","title":"<code>server(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Create a flwr.Server object.</p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>@abstractmethod\ndef server(self, **kwargs: Any) -&gt; Server:\n    \"\"\"Create a flwr.Server object.\"\"\"\n    ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.fl_task.BaseFLTask.simulate","title":"<code>simulate(num_clients, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Simulate the FL task.</p> <p>Either use flwr's simulation tools, or create our own here.</p> Source code in <code>src/fed_rag/base/fl_task.py</code> <pre><code>@abstractmethod\ndef simulate(self, num_clients: int, **kwargs: Any) -&gt; Any:\n    \"\"\"Simulate the FL task.\n\n    Either use flwr's simulation tools, or create our own here.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"references/#src.fed_rag.base.generator","title":"<code>generator</code>","text":"<p>Base Generator</p>"},{"location":"references/#src.fed_rag.base.generator.BaseGenerator","title":"<code>BaseGenerator</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Base Generator Class.</p> Source code in <code>src/fed_rag/base/generator.py</code> <pre><code>class BaseGenerator(BaseModel, ABC):\n    \"\"\"Base Generator Class.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @abstractmethod\n    def generate(self, query: str, context: str, **kwargs: dict) -&gt; str:\n        \"\"\"Generate an output from a given query and context.\"\"\"\n\n    @property\n    @abstractmethod\n    def model(self) -&gt; torch.nn.Module:\n        \"\"\"Model associated with this generator.\"\"\"\n\n    @property\n    @abstractmethod\n    def tokenizer(self) -&gt; BaseTokenizer:\n        \"\"\"Tokenizer associated with this generator.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.generator.BaseGenerator.model","title":"<code>model</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Model associated with this generator.</p>"},{"location":"references/#src.fed_rag.base.generator.BaseGenerator.tokenizer","title":"<code>tokenizer</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Tokenizer associated with this generator.</p>"},{"location":"references/#src.fed_rag.base.generator.BaseGenerator.generate","title":"<code>generate(query, context, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Generate an output from a given query and context.</p> Source code in <code>src/fed_rag/base/generator.py</code> <pre><code>@abstractmethod\ndef generate(self, query: str, context: str, **kwargs: dict) -&gt; str:\n    \"\"\"Generate an output from a given query and context.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.knowledge_store","title":"<code>knowledge_store</code>","text":"<p>Base Knowledge Store</p>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore","title":"<code>BaseKnowledgeStore</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Base Knowledge Store Class.</p> Source code in <code>src/fed_rag/base/knowledge_store.py</code> <pre><code>class BaseKnowledgeStore(BaseModel, ABC):\n    \"\"\"Base Knowledge Store Class.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @abstractmethod\n    def load_node(self, node: KnowledgeNode) -&gt; None:\n        \"\"\"Load a KnowledgeNode into the KnowledgeStore.\"\"\"\n\n    @abstractmethod\n    def load_nodes(self, nodes: list[KnowledgeNode]) -&gt; None:\n        \"\"\"Load multiple KnowledgeNodes in batch.\"\"\"\n\n    @abstractmethod\n    def retrieve(\n        self, query_emb: list[float], top_k: int\n    ) -&gt; list[tuple[float, KnowledgeNode]]:\n        \"\"\"Retrieve top-k nodes from KnowledgeStore against a provided user query.\n\n        Returns:\n            A list of tuples where the first element represents the similarity score\n            of the node to the query, and the second element is the node itself.\n        \"\"\"\n\n    @abstractmethod\n    def delete_node(self, node_id: str) -&gt; bool:\n        \"\"\"Remove a node from the KnowledgeStore by ID, returning success status.\"\"\"\n\n    @abstractmethod\n    def clear(self) -&gt; None:\n        \"\"\"Clear all nodes from the KnowledgeStore.\"\"\"\n\n    @property\n    @abstractmethod\n    def count(self) -&gt; int:\n        \"\"\"Return the number of nodes in the store.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore.count","title":"<code>count</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the number of nodes in the store.</p>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore.clear","title":"<code>clear()</code>  <code>abstractmethod</code>","text":"<p>Clear all nodes from the KnowledgeStore.</p> Source code in <code>src/fed_rag/base/knowledge_store.py</code> <pre><code>@abstractmethod\ndef clear(self) -&gt; None:\n    \"\"\"Clear all nodes from the KnowledgeStore.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore.delete_node","title":"<code>delete_node(node_id)</code>  <code>abstractmethod</code>","text":"<p>Remove a node from the KnowledgeStore by ID, returning success status.</p> Source code in <code>src/fed_rag/base/knowledge_store.py</code> <pre><code>@abstractmethod\ndef delete_node(self, node_id: str) -&gt; bool:\n    \"\"\"Remove a node from the KnowledgeStore by ID, returning success status.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore.load_node","title":"<code>load_node(node)</code>  <code>abstractmethod</code>","text":"<p>Load a KnowledgeNode into the KnowledgeStore.</p> Source code in <code>src/fed_rag/base/knowledge_store.py</code> <pre><code>@abstractmethod\ndef load_node(self, node: KnowledgeNode) -&gt; None:\n    \"\"\"Load a KnowledgeNode into the KnowledgeStore.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore.load_nodes","title":"<code>load_nodes(nodes)</code>  <code>abstractmethod</code>","text":"<p>Load multiple KnowledgeNodes in batch.</p> Source code in <code>src/fed_rag/base/knowledge_store.py</code> <pre><code>@abstractmethod\ndef load_nodes(self, nodes: list[KnowledgeNode]) -&gt; None:\n    \"\"\"Load multiple KnowledgeNodes in batch.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.knowledge_store.BaseKnowledgeStore.retrieve","title":"<code>retrieve(query_emb, top_k)</code>  <code>abstractmethod</code>","text":"<p>Retrieve top-k nodes from KnowledgeStore against a provided user query.</p> <p>Returns:</p> Type Description <code>list[tuple[float, KnowledgeNode]]</code> <p>A list of tuples where the first element represents the similarity score</p> <code>list[tuple[float, KnowledgeNode]]</code> <p>of the node to the query, and the second element is the node itself.</p> Source code in <code>src/fed_rag/base/knowledge_store.py</code> <pre><code>@abstractmethod\ndef retrieve(\n    self, query_emb: list[float], top_k: int\n) -&gt; list[tuple[float, KnowledgeNode]]:\n    \"\"\"Retrieve top-k nodes from KnowledgeStore against a provided user query.\n\n    Returns:\n        A list of tuples where the first element represents the similarity score\n        of the node to the query, and the second element is the node itself.\n    \"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.retriever","title":"<code>retriever</code>","text":"<p>Base Retriever</p>"},{"location":"references/#src.fed_rag.base.retriever.BaseRetriever","title":"<code>BaseRetriever</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Base Retriever Class.</p> Source code in <code>src/fed_rag/base/retriever.py</code> <pre><code>class BaseRetriever(BaseModel, ABC):\n    \"\"\"Base Retriever Class.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @abstractmethod\n    def encode_query(\n        self, query: str | list[str], **kwargs: Any\n    ) -&gt; torch.Tensor:\n        \"\"\"Encode query.\"\"\"\n\n    @abstractmethod\n    def encode_context(\n        self, context: str | list[str], **kwargs: Any\n    ) -&gt; torch.Tensor:\n        \"\"\"Encode context.\"\"\"\n\n    @property\n    @abstractmethod\n    def encoder(self) -&gt; torch.nn.Module | None:\n        \"\"\"PyTorch model associated with the encoder associated with retriever.\"\"\"\n\n    @property\n    @abstractmethod\n    def query_encoder(self) -&gt; torch.nn.Module | None:\n        \"\"\"PyTorch model associated with the query encoder associated with retriever.\"\"\"\n\n    @property\n    @abstractmethod\n    def context_encoder(self) -&gt; torch.nn.Module | None:\n        \"\"\"PyTorch model associated with the context encoder associated with retriever.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.retriever.BaseRetriever.context_encoder","title":"<code>context_encoder</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>PyTorch model associated with the context encoder associated with retriever.</p>"},{"location":"references/#src.fed_rag.base.retriever.BaseRetriever.encoder","title":"<code>encoder</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>PyTorch model associated with the encoder associated with retriever.</p>"},{"location":"references/#src.fed_rag.base.retriever.BaseRetriever.query_encoder","title":"<code>query_encoder</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>PyTorch model associated with the query encoder associated with retriever.</p>"},{"location":"references/#src.fed_rag.base.retriever.BaseRetriever.encode_context","title":"<code>encode_context(context, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Encode context.</p> Source code in <code>src/fed_rag/base/retriever.py</code> <pre><code>@abstractmethod\ndef encode_context(\n    self, context: str | list[str], **kwargs: Any\n) -&gt; torch.Tensor:\n    \"\"\"Encode context.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.retriever.BaseRetriever.encode_query","title":"<code>encode_query(query, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Encode query.</p> Source code in <code>src/fed_rag/base/retriever.py</code> <pre><code>@abstractmethod\ndef encode_query(\n    self, query: str | list[str], **kwargs: Any\n) -&gt; torch.Tensor:\n    \"\"\"Encode query.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.tokenizer","title":"<code>tokenizer</code>","text":"<p>Base Tokenizer</p>"},{"location":"references/#src.fed_rag.base.tokenizer.BaseTokenizer","title":"<code>BaseTokenizer</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Base Tokenizer Class.</p> Source code in <code>src/fed_rag/base/tokenizer.py</code> <pre><code>class BaseTokenizer(BaseModel, ABC):\n    \"\"\"Base Tokenizer Class.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @abstractmethod\n    def encode(self, input: str, **kwargs: dict) -&gt; list[int]:\n        \"\"\"Encode the input string into list of integers.\"\"\"\n\n    @abstractmethod\n    def decode(self, input_ids: str, **kwargs: dict) -&gt; str:\n        \"\"\"Decode the input token ids into a string.\"\"\"\n\n    @property\n    @abstractmethod\n    def unwrapped(self) -&gt; Any:\n        \"\"\"Return the underlying tokenizer if there is one.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.tokenizer.BaseTokenizer.unwrapped","title":"<code>unwrapped</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the underlying tokenizer if there is one.</p>"},{"location":"references/#src.fed_rag.base.tokenizer.BaseTokenizer.decode","title":"<code>decode(input_ids, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Decode the input token ids into a string.</p> Source code in <code>src/fed_rag/base/tokenizer.py</code> <pre><code>@abstractmethod\ndef decode(self, input_ids: str, **kwargs: dict) -&gt; str:\n    \"\"\"Decode the input token ids into a string.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.tokenizer.BaseTokenizer.encode","title":"<code>encode(input, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Encode the input string into list of integers.</p> Source code in <code>src/fed_rag/base/tokenizer.py</code> <pre><code>@abstractmethod\ndef encode(self, input: str, **kwargs: dict) -&gt; list[int]:\n    \"\"\"Encode the input string into list of integers.\"\"\"\n</code></pre>"},{"location":"references/#src.fed_rag.base.trainer_config","title":"<code>trainer_config</code>","text":"<p>Base Trainer Config</p>"},{"location":"references/#src.fed_rag.base.trainer_config.BaseTrainerConfig","title":"<code>BaseTrainerConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/fed_rag/base/trainer_config.py</code> <pre><code>class BaseTrainerConfig(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    net: Any\n    train_data: Any\n    val_data: Any\n    _extra_train_kwargs: Dict[str, Any] = PrivateAttr(\n        default_factory=dict\n    )  # additional kwargs\n\n    def __init__(self, **params: Any):\n        \"\"\"__init__.\n\n        Sets specified fields and private attrs of the TrainerConfig and then\n        stores any additional passed params in _extra_train_kwargs.\n        \"\"\"\n        fields = {}\n        private_attrs = {}\n        extra_train_kwargs = {}\n        for k, v in params.items():\n            if k in self.model_fields:\n                fields[k] = v\n            elif k in self.__private_attributes__:\n                private_attrs[k] = v\n            else:\n                extra_train_kwargs[k] = v\n        super().__init__(**fields)\n        for private_attr, value in private_attrs.items():\n            super().__setattr__(private_attr, value)\n        if extra_train_kwargs:\n            self._extra_train_kwargs.update(extra_train_kwargs)\n\n    @model_serializer(mode=\"wrap\")\n    def custom_model_dump(self, handler: Any) -&gt; Dict[str, Any]:\n        data = handler(self)\n        data = cast(Dict[str, Any], data)\n        # include _extra_train_kwargs in serialization\n        if self._extra_train_kwargs:\n            data[\"_extra_train_kwargs\"] = self._extra_train_kwargs\n        return data  # type: ignore[no-any-return]\n\n    def __getattr__(self, __name: str) -&gt; Any:\n        if (\n            __name in self.__private_attributes__\n            or __name in self.model_fields\n        ):\n            return super().__getattr__(__name)  # type: ignore\n        else:\n            try:\n                return self._data[__name]\n            except KeyError:\n                raise AttributeError(\n                    f\"'{self.__class__.__name__}' object has no attribute '{__name}'\"\n                )\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        if name in self.__private_attributes__ or name in self.model_fields:\n            super().__setattr__(name, value)\n        else:\n            self._extra_train_kwargs.__setitem__(name, value)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        return self._extra_train_kwargs[key]\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        self._extra_train_kwargs[key] = value\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        return self._extra_train_kwargs.get(key, default)\n\n    def __contains__(self, key: str) -&gt; bool:\n        return key in self._extra_train_kwargs\n</code></pre>"},{"location":"references/#src.fed_rag.base.trainer_config.BaseTrainerConfig.__init__","title":"<code>__init__(**params)</code>","text":"<p>init.</p> <p>Sets specified fields and private attrs of the TrainerConfig and then stores any additional passed params in _extra_train_kwargs.</p> Source code in <code>src/fed_rag/base/trainer_config.py</code> <pre><code>def __init__(self, **params: Any):\n    \"\"\"__init__.\n\n    Sets specified fields and private attrs of the TrainerConfig and then\n    stores any additional passed params in _extra_train_kwargs.\n    \"\"\"\n    fields = {}\n    private_attrs = {}\n    extra_train_kwargs = {}\n    for k, v in params.items():\n        if k in self.model_fields:\n            fields[k] = v\n        elif k in self.__private_attributes__:\n            private_attrs[k] = v\n        else:\n            extra_train_kwargs[k] = v\n    super().__init__(**fields)\n    for private_attr, value in private_attrs.items():\n        super().__setattr__(private_attr, value)\n    if extra_train_kwargs:\n        self._extra_train_kwargs.update(extra_train_kwargs)\n</code></pre>"},{"location":"references/#src.fed_rag.decorators","title":"<code>decorators</code>","text":"<p>Decorators</p>"},{"location":"references/#src.fed_rag.decorators.tester","title":"<code>tester</code>","text":"<p>Tester Decorators</p>"},{"location":"references/#src.fed_rag.decorators.trainer","title":"<code>trainer</code>","text":"<p>Trainer Decorators</p>"},{"location":"references/#src.fed_rag.exceptions","title":"<code>exceptions</code>","text":""},{"location":"references/#src.fed_rag.exceptions.MissingRequiredNetParam","title":"<code>MissingRequiredNetParam</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when invoking fl_task.server without passing the specified model/net param.</p> Source code in <code>src/fed_rag/exceptions/fl_tasks.py</code> <pre><code>class MissingRequiredNetParam(Exception):\n    \"\"\"Raised when invoking fl_task.server without passing the specified model/net param.\"\"\"\n\n    pass\n</code></pre>"},{"location":"references/#src.fed_rag.exceptions.NetTypeMismatch","title":"<code>NetTypeMismatch</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a <code>trainer</code> and <code>tester</code> spec have differing <code>net_parameter_class_name</code>.</p> <p>This indicates that the these methods have different types for the <code>net_parameter</code>.</p> Source code in <code>src/fed_rag/exceptions/fl_tasks.py</code> <pre><code>class NetTypeMismatch(Exception):\n    \"\"\"Raised when a `trainer` and `tester` spec have differing `net_parameter_class_name`.\n\n    This indicates that the these methods have different types for the `net_parameter`.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"references/#src.fed_rag.exceptions.fl_tasks","title":"<code>fl_tasks</code>","text":""},{"location":"references/#src.fed_rag.exceptions.fl_tasks.MissingRequiredNetParam","title":"<code>MissingRequiredNetParam</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when invoking fl_task.server without passing the specified model/net param.</p> Source code in <code>src/fed_rag/exceptions/fl_tasks.py</code> <pre><code>class MissingRequiredNetParam(Exception):\n    \"\"\"Raised when invoking fl_task.server without passing the specified model/net param.\"\"\"\n\n    pass\n</code></pre>"},{"location":"references/#src.fed_rag.exceptions.fl_tasks.NetTypeMismatch","title":"<code>NetTypeMismatch</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a <code>trainer</code> and <code>tester</code> spec have differing <code>net_parameter_class_name</code>.</p> <p>This indicates that the these methods have different types for the <code>net_parameter</code>.</p> Source code in <code>src/fed_rag/exceptions/fl_tasks.py</code> <pre><code>class NetTypeMismatch(Exception):\n    \"\"\"Raised when a `trainer` and `tester` spec have differing `net_parameter_class_name`.\n\n    This indicates that the these methods have different types for the `net_parameter`.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"references/#src.fed_rag.exceptions.inspectors","title":"<code>inspectors</code>","text":"<p>Exceptions for inspectors</p>"},{"location":"references/#src.fed_rag.fl_tasks","title":"<code>fl_tasks</code>","text":""},{"location":"references/#src.fed_rag.fl_tasks.huggingface","title":"<code>huggingface</code>","text":"<p>HuggingFace FL Task.</p> <p>NOTE: Using this module requires the <code>huggingface</code> extra to be installed.</p>"},{"location":"references/#src.fed_rag.fl_tasks.pytorch","title":"<code>pytorch</code>","text":"<p>PyTorch FL Task</p>"},{"location":"references/#src.fed_rag.generators","title":"<code>generators</code>","text":""},{"location":"references/#src.fed_rag.generators.hf_peft_model","title":"<code>hf_peft_model</code>","text":"<p>HuggingFace PeftModel Generator</p>"},{"location":"references/#src.fed_rag.generators.hf_peft_model.HFPeftModelGenerator","title":"<code>HFPeftModelGenerator</code>","text":"<p>               Bases: <code>BaseGenerator</code></p> <p>HFPeftModelGenerator Class.</p> <p>NOTE: this class supports loading PeftModel's from HF Hub or from local. TODO: support loading custom models via a <code>~peft.Config</code> and <code>~peft.get_peft_model</code></p> Source code in <code>src/fed_rag/generators/hf_peft_model.py</code> <pre><code>class HFPeftModelGenerator(BaseGenerator):\n    \"\"\"HFPeftModelGenerator Class.\n\n    NOTE: this class supports loading PeftModel's from HF Hub or from local.\n    TODO: support loading custom models via a `~peft.Config` and `~peft.get_peft_model`\n    \"\"\"\n\n    model_config = ConfigDict(protected_namespaces=(\"pydantic_model_\",))\n    model_name: str = Field(\n        description=\"Name of Peft model. Used for loading model from HF hub or local.\"\n    )\n    base_model_name: str = Field(\n        description=\"Name of the frozen HuggingFace base model. Used for loading the model from HF hub or local.\"\n    )\n    generation_config: \"GenerationConfig\" = Field(\n        description=\"The generation config used for generating with the PreTrainedModel.\"\n    )\n    load_model_kwargs: dict = Field(\n        description=\"Optional kwargs dict for loading peft model from HF. Defaults to None.\",\n        default_factory=dict,\n    )\n    load_base_model_kwargs: dict = Field(\n        description=\"Optional kwargs dict for loading base model from HF. Defaults to None.\",\n        default_factory=dict,\n    )\n    prompt_template: str = Field(description=\"Prompt template for RAG.\")\n    _model: Optional[\"PeftModel\"] = PrivateAttr(default=None)\n    _tokenizer: HFPretrainedTokenizer | None = PrivateAttr(default=None)\n\n    def __init__(\n        self,\n        model_name: str,\n        base_model_name: str,\n        generation_config: Optional[\"GenerationConfig\"] = None,\n        prompt_template: str | None = None,\n        load_model_kwargs: dict | None = None,\n        load_base_model_kwargs: dict | None = None,\n        load_model_at_init: bool = True,\n    ):\n        if not _has_huggingface:\n            msg = (\n                f\"`{self.__class__.__name__}` requires `huggingface` extra to be installed. \"\n                \"To fix please run `pip install fed-rag[huggingface]`.\"\n            )\n            raise ValueError(msg)\n\n        generation_config = (\n            generation_config if generation_config else GenerationConfig()\n        )\n        prompt_template = (\n            prompt_template if prompt_template else DEFAULT_PROMPT_TEMPLATE\n        )\n        super().__init__(\n            model_name=model_name,\n            base_model_name=base_model_name,\n            generation_config=generation_config,\n            prompt_template=prompt_template,\n            load_model_kwargs=load_model_kwargs if load_model_kwargs else {},\n            load_base_model_kwargs=(\n                load_base_model_kwargs if load_base_model_kwargs else {}\n            ),\n        )\n        self._tokenizer = HFPretrainedTokenizer(\n            model_name=base_model_name, load_model_at_init=load_model_at_init\n        )\n        if load_model_at_init:\n            self._model = self._load_model_from_hf()\n\n    def _load_model_from_hf(self, **kwargs: Any) -&gt; \"PeftModel\":\n        load_base_kwargs = self.load_base_model_kwargs\n        load_kwargs = self.load_model_kwargs\n        load_kwargs.update(kwargs)\n        self.load_model_kwargs = load_kwargs  # update load_model_kwargs\n        base_model = AutoModelForCausalLM.from_pretrained(\n            self.base_model_name, **load_base_kwargs\n        )\n\n        if \"quantization_config\" in load_base_kwargs:\n            # preprocess model for kbit fine-tuning\n            # https://huggingface.co/docs/peft/developer_guides/quantization\n            base_model = prepare_model_for_kbit_training(base_model)\n\n        return PeftModel.from_pretrained(\n            base_model, self.model_name, **load_kwargs\n        )\n\n    @property\n    def model(self) -&gt; \"PeftModel\":\n        if self._model is None:\n            # load HF PeftModel\n            self._model = self._load_model_from_hf()\n        return self._model\n\n    @model.setter\n    def model(self, value: \"PeftModel\") -&gt; None:\n        self._model = value\n\n    @property\n    def tokenizer(self) -&gt; HFPretrainedTokenizer:\n        return self._tokenizer\n\n    # generate\n    def generate(self, query: str, context: str, **kwargs: Any) -&gt; str:\n        formatted_query = self.prompt_template.format(\n            question=query, context=context\n        )\n\n        # encode query\n        tokenizer_result = self.tokenizer.unwrapped(\n            formatted_query, return_tensors=\"pt\"\n        )\n        inputs: torch.Tensor = tokenizer_result.input_ids\n        inputs = inputs.to(self.model.device)\n\n        # generate\n        generated_ids = self.model.generate(\n            inputs=inputs,\n            generation_config=self.generation_config,\n            tokenizer=self.tokenizer.unwrapped,\n            **kwargs,\n        )\n\n        # decode tokens\n        outputs: list[str] = self.tokenizer.unwrapped.batch_decode(\n            generated_ids, skip_special_tokens=True\n        )\n        return outputs[0]\n</code></pre>"},{"location":"references/#src.fed_rag.generators.hf_pretrained_model","title":"<code>hf_pretrained_model</code>","text":"<p>HuggingFace PretrainedModel Generator</p>"},{"location":"references/#src.fed_rag.inspectors","title":"<code>inspectors</code>","text":""},{"location":"references/#src.fed_rag.inspectors.common","title":"<code>common</code>","text":"<p>Common abstractions for inspectors</p>"},{"location":"references/#src.fed_rag.inspectors.huggingface","title":"<code>huggingface</code>","text":""},{"location":"references/#src.fed_rag.inspectors.huggingface.tester","title":"<code>tester</code>","text":"<p>PyTorch Tester Inspector</p>"},{"location":"references/#src.fed_rag.inspectors.huggingface.trainer","title":"<code>trainer</code>","text":"<p>HuggingFace Trainer Inspector</p>"},{"location":"references/#src.fed_rag.inspectors.pytorch","title":"<code>pytorch</code>","text":""},{"location":"references/#src.fed_rag.inspectors.pytorch.tester","title":"<code>tester</code>","text":"<p>PyTorch Tester Inspector</p>"},{"location":"references/#src.fed_rag.inspectors.pytorch.trainer","title":"<code>trainer</code>","text":"<p>PyTorch Trainer Inspector</p>"},{"location":"references/#src.fed_rag.knowledge_stores","title":"<code>knowledge_stores</code>","text":""},{"location":"references/#src.fed_rag.knowledge_stores.in_memory","title":"<code>in_memory</code>","text":"<p>In Memory Knowledge Store</p>"},{"location":"references/#src.fed_rag.knowledge_stores.in_memory.InMemoryKnowledgeStore","title":"<code>InMemoryKnowledgeStore</code>","text":"<p>               Bases: <code>BaseKnowledgeStore</code></p> <p>InMemoryKnowledgeStore Class.</p> Source code in <code>src/fed_rag/knowledge_stores/in_memory.py</code> <pre><code>class InMemoryKnowledgeStore(BaseKnowledgeStore):\n    \"\"\"InMemoryKnowledgeStore Class.\"\"\"\n\n    _data: dict[str, KnowledgeNode] = PrivateAttr(default_factory=dict)\n\n    @classmethod\n    def from_nodes(cls, nodes: list[KnowledgeNode]) -&gt; Self:\n        instance = cls()\n        instance.load_nodes(nodes)\n        return instance\n\n    def load_node(self, node: KnowledgeNode) -&gt; None:\n        if node.node_id not in self._data:\n            self._data[node.node_id] = node\n\n    def load_nodes(self, nodes: list[KnowledgeNode]) -&gt; None:\n        for node in nodes:\n            self.load_node(node)\n\n    def retrieve(\n        self, query_emb: list[float], top_k: int\n    ) -&gt; list[tuple[float, KnowledgeNode]]:\n        all_nodes = list(self._data.values())\n        node_ids_and_scores = _get_top_k_nodes(\n            nodes=all_nodes, query_emb=query_emb, top_k=top_k\n        )\n        return [(el[1], self._data[el[0]]) for el in node_ids_and_scores]\n\n    def delete_node(self, node_id: str) -&gt; bool:\n        if node_id in self._data:\n            del self._data[node_id]\n            return True\n        else:\n            return False\n\n    def clear(self) -&gt; None:\n        self._data = {}\n\n    @property\n    def count(self) -&gt; int:\n        return len(self._data)\n</code></pre>"},{"location":"references/#src.fed_rag.retrievers","title":"<code>retrievers</code>","text":""},{"location":"references/#src.fed_rag.retrievers.hf_sentence_transformer","title":"<code>hf_sentence_transformer</code>","text":"<p>HuggingFace SentenceTransformer Retriever</p>"},{"location":"references/#src.fed_rag.tokenizers","title":"<code>tokenizers</code>","text":""},{"location":"references/#src.fed_rag.tokenizers.hf_pretrained_tokenizer","title":"<code>hf_pretrained_tokenizer</code>","text":"<p>HuggingFace PretrainedTokenizer</p>"},{"location":"references/#src.fed_rag.trainer_configs","title":"<code>trainer_configs</code>","text":""},{"location":"references/#src.fed_rag.trainer_configs.pytorch","title":"<code>pytorch</code>","text":"<p>PyTorch Trainer Config</p>"},{"location":"references/#src.fed_rag.types","title":"<code>types</code>","text":""},{"location":"references/#src.fed_rag.types.knowledge_node","title":"<code>knowledge_node</code>","text":"<p>Knowledge Node</p>"},{"location":"references/#src.fed_rag.types.knowledge_node.KnowledgeNode","title":"<code>KnowledgeNode</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/fed_rag/types/knowledge_node.py</code> <pre><code>class KnowledgeNode(BaseModel):\n    model_config = ConfigDict(\n        # ensures that validation is performed for defaulted None values\n        validate_default=True\n    )\n    node_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    embedding: list[float] = Field(\n        description=\"Encoded representation of node. If multimodal type, then this is shared embedding between image and text.\"\n    )\n    node_type: NodeType = Field(description=\"Type of node.\")\n    text_content: str | None = Field(\n        description=\"Text content. Used for TEXT and potentially MULTIMODAL node types.\",\n        default=None,\n    )\n    image_content: bytes | None = Field(\n        description=\"Image content as binary data (decoded from base64)\",\n        default=None,\n    )\n    metadata: dict = Field(\n        description=\"Metadata for node.\", default_factory=dict\n    )\n\n    # validators\n    @field_validator(\"text_content\", mode=\"before\")\n    @classmethod\n    def validate_text_content(\n        cls, value: str | None, info: ValidationInfo\n    ) -&gt; str | None:\n        node_type = info.data.get(\"node_type\")\n        node_type = cast(NodeType, node_type)\n        if node_type == NodeType.TEXT and value is None:\n            raise ValueError(\"NodeType == 'text', but text_content is None.\")\n\n        if node_type == NodeType.MULTIMODAL and value is None:\n            raise ValueError(\n                \"NodeType == 'multimodal', but text_content is None.\"\n            )\n\n        return value\n\n    @field_validator(\"image_content\", mode=\"after\")\n    @classmethod\n    def validate_image_content(\n        cls, value: str | None, info: ValidationInfo\n    ) -&gt; str | None:\n        node_type = info.data.get(\"node_type\")\n        node_type = cast(NodeType, node_type)\n        if node_type == NodeType.IMAGE:\n            if value is None:\n                raise ValueError(\n                    \"NodeType == 'image', but image_content is None.\"\n                )\n\n        if node_type == NodeType.MULTIMODAL:\n            if value is None:\n                raise ValueError(\n                    \"NodeType == 'multimodal', but image_content is None.\"\n                )\n\n        return value\n\n    def get_content(self) -&gt; NodeContent:\n        \"\"\"Return dict of node content.\"\"\"\n        content: NodeContent = {\n            \"image_content\": self.image_content,\n            \"text_content\": self.text_content,\n        }\n        return content\n</code></pre>"},{"location":"references/#src.fed_rag.types.knowledge_node.KnowledgeNode.get_content","title":"<code>get_content()</code>","text":"<p>Return dict of node content.</p> Source code in <code>src/fed_rag/types/knowledge_node.py</code> <pre><code>def get_content(self) -&gt; NodeContent:\n    \"\"\"Return dict of node content.\"\"\"\n    content: NodeContent = {\n        \"image_content\": self.image_content,\n        \"text_content\": self.text_content,\n    }\n    return content\n</code></pre>"},{"location":"references/#src.fed_rag.types.rag_system","title":"<code>rag_system</code>","text":"<p>RAG System</p>"},{"location":"references/#src.fed_rag.types.rag_system.RAGSystem","title":"<code>RAGSystem</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/fed_rag/types/rag_system.py</code> <pre><code>class RAGSystem(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    generator: BaseGenerator\n    retriever: BaseRetriever\n    knowledge_store: BaseKnowledgeStore\n    rag_config: RAGConfig\n\n    def query(self, query: str) -&gt; RAGResponse:\n        \"\"\"Query the RAG system.\"\"\"\n        source_nodes = self.retrieve(query)\n        context = self._format_context(source_nodes)\n        response = self.generate(query=query, context=context)\n        return RAGResponse(source_nodes=source_nodes, response=response)\n\n    def retrieve(self, query: str) -&gt; list[SourceNode]:\n        \"\"\"Retrieve from KnowledgeStore.\"\"\"\n        query_emb: list[float] = self.retriever.encode_query(query).tolist()\n        raw_retrieval_result = self.knowledge_store.retrieve(\n            query_emb=query_emb, top_k=self.rag_config.top_k\n        )\n        return [\n            SourceNode(score=el[0], node=el[1]) for el in raw_retrieval_result\n        ]\n\n    def generate(self, query: str, context: str) -&gt; str:\n        \"\"\"Generate response to query with context.\"\"\"\n        return self.generator.generate(query=query, context=context)  # type: ignore\n\n    def _format_context(self, source_nodes: list[SourceNode]) -&gt; str:\n        \"\"\"Format the context from the source nodes.\"\"\"\n        # TODO: how to format image context\n        return self.rag_config.context_separator.join(\n            [node.get_content()[\"text_content\"] for node in source_nodes]\n        )\n</code></pre>"},{"location":"references/#src.fed_rag.types.rag_system.RAGSystem.generate","title":"<code>generate(query, context)</code>","text":"<p>Generate response to query with context.</p> Source code in <code>src/fed_rag/types/rag_system.py</code> <pre><code>def generate(self, query: str, context: str) -&gt; str:\n    \"\"\"Generate response to query with context.\"\"\"\n    return self.generator.generate(query=query, context=context)  # type: ignore\n</code></pre>"},{"location":"references/#src.fed_rag.types.rag_system.RAGSystem.query","title":"<code>query(query)</code>","text":"<p>Query the RAG system.</p> Source code in <code>src/fed_rag/types/rag_system.py</code> <pre><code>def query(self, query: str) -&gt; RAGResponse:\n    \"\"\"Query the RAG system.\"\"\"\n    source_nodes = self.retrieve(query)\n    context = self._format_context(source_nodes)\n    response = self.generate(query=query, context=context)\n    return RAGResponse(source_nodes=source_nodes, response=response)\n</code></pre>"},{"location":"references/#src.fed_rag.types.rag_system.RAGSystem.retrieve","title":"<code>retrieve(query)</code>","text":"<p>Retrieve from KnowledgeStore.</p> Source code in <code>src/fed_rag/types/rag_system.py</code> <pre><code>def retrieve(self, query: str) -&gt; list[SourceNode]:\n    \"\"\"Retrieve from KnowledgeStore.\"\"\"\n    query_emb: list[float] = self.retriever.encode_query(query).tolist()\n    raw_retrieval_result = self.knowledge_store.retrieve(\n        query_emb=query_emb, top_k=self.rag_config.top_k\n    )\n    return [\n        SourceNode(score=el[0], node=el[1]) for el in raw_retrieval_result\n    ]\n</code></pre>"},{"location":"references/#src.fed_rag.types.rag_system.SourceNode","title":"<code>SourceNode</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/fed_rag/types/rag_system.py</code> <pre><code>class SourceNode(BaseModel):\n    score: float\n    node: KnowledgeNode\n\n    def __getattr__(self, __name: str) -&gt; Any:\n        \"\"\"Convenient wrapper on getattr of associated node.\"\"\"\n        return getattr(self.node, __name)\n</code></pre>"},{"location":"references/#src.fed_rag.types.rag_system.SourceNode.__getattr__","title":"<code>__getattr__(__name)</code>","text":"<p>Convenient wrapper on getattr of associated node.</p> Source code in <code>src/fed_rag/types/rag_system.py</code> <pre><code>def __getattr__(self, __name: str) -&gt; Any:\n    \"\"\"Convenient wrapper on getattr of associated node.\"\"\"\n    return getattr(self.node, __name)\n</code></pre>"},{"location":"references/#src.fed_rag.types.results","title":"<code>results</code>","text":"<p>TesterResult</p>"},{"location":"references/#src.fed_rag.utils","title":"<code>utils</code>","text":""},{"location":"references/#src.fed_rag.utils.data","title":"<code>data</code>","text":""},{"location":"references/#src.fed_rag.utils.data.build_finetune_dataset","title":"<code>build_finetune_dataset(rag_system, examples, eos_token_id, finetune_example_template=DEFAULT_FINETUNE_EXAMPLE_TEMPLATE, query_key='query', answer_key='answer', return_dataset=ReturnType.PYTORCH)</code>","text":"<p>Generates the finetuning dataset using the supplied rag_system and examples.</p> Source code in <code>src/fed_rag/utils/data/_functions.py</code> <pre><code>def build_finetune_dataset(\n    rag_system: RAGSystem,\n    examples: Sequence[dict],\n    eos_token_id: int,\n    finetune_example_template: str = DEFAULT_FINETUNE_EXAMPLE_TEMPLATE,\n    query_key: str = \"query\",\n    answer_key: str = \"answer\",\n    return_dataset: ReturnType = ReturnType.PYTORCH,\n) -&gt; Any:\n    \"\"\"Generates the finetuning dataset using the supplied rag_system and examples.\"\"\"\n\n    if (\n        isinstance(return_dataset, str)\n        and return_dataset not in ReturnType._value2member_map_.keys()\n    ):\n        raise ValueError(\n            \"Invalid `return_type` specified.\"\n        )  # TODO: give a proper exception to this\n\n    inputs_list = []\n    targets_list = []\n    finetuning_instances = []\n    for example in examples:\n        # retrieve\n        source_nodes = rag_system.retrieve(query=example[query_key])\n        total_sum_scores = sum(s.score for s in source_nodes)\n\n        # parallel in-context retrieval-augmentation creates\n        # top_k separated finetuning instances\n        for source in source_nodes:\n            finetune_instance_text = finetune_example_template.format(\n                query=example[query_key],\n                answer=example[answer_key],\n                context=source.node.get_content()[\"text_content\"],\n            )\n            finetuning_instances.append(finetune_instance_text)\n            _weight = source.score / total_sum_scores\n\n            # tokenize to get input_ids and target_ids\n            tokenizer = rag_system.generator.tokenizer\n            input_ids = tokenizer.encode(finetune_instance_text)\n            target_ids = input_ids[1:] + [eos_token_id]\n\n            inputs_list.append(input_ids)\n            targets_list.append(target_ids)\n\n    if return_dataset == ReturnType.TEXT:\n        return finetuning_instances\n    elif return_dataset == ReturnType.PYTORCH:\n        return PyTorchRAGFinetuningDataset(\n            input_ids=[torch.Tensor(el) for el in inputs_list],\n            target_ids=[torch.Tensor(el) for el in targets_list],\n        )\n    elif return_dataset == ReturnType.HUGGINGFACE:\n        # needs `fed-rag[huggingface]` extra to be installed\n        # this import will fail if not installed\n        from fed_rag.utils.data.finetuning_datasets.huggingface import (\n            HuggingfaceRAGFinetuningDataset,\n        )\n\n        return HuggingfaceRAGFinetuningDataset.from_inputs(\n            input_ids=inputs_list, target_ids=targets_list\n        )\n    else:\n        assert_never(return_dataset)  # pragma: no cover\n</code></pre>"},{"location":"references/#src.fed_rag.utils.data.finetuning_datasets","title":"<code>finetuning_datasets</code>","text":""},{"location":"references/#src.fed_rag.utils.data.finetuning_datasets.PyTorchRAGFinetuningDataset","title":"<code>PyTorchRAGFinetuningDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>PyTorch RAG Fine-Tuning Dataset Class.</p> <p>Parameters:</p> Name Type Description Default <code>Dataset</code> <code>_type_</code> <p>description</p> required Source code in <code>src/fed_rag/utils/data/finetuning_datasets/pytorch.py</code> <pre><code>class PyTorchRAGFinetuningDataset(Dataset):\n    \"\"\"PyTorch RAG Fine-Tuning Dataset Class.\n\n    Args:\n        Dataset (_type_): _description_\n    \"\"\"\n\n    def __init__(\n        self, input_ids: list[torch.Tensor], target_ids: list[torch.Tensor]\n    ):\n        self.input_ids = input_ids\n        self.target_ids = target_ids\n\n    def __len__(self) -&gt; int:\n        return len(self.input_ids)\n\n    def __getitem__(self, idx: int) -&gt; Any:\n        return self.input_ids[idx], self.target_ids[idx]\n</code></pre>"},{"location":"references/#src.fed_rag.utils.data.finetuning_datasets.huggingface","title":"<code>huggingface</code>","text":"<p>HuggingFace RAG Finetuning Dataset</p>"},{"location":"references/#src.fed_rag.utils.data.finetuning_datasets.huggingface.HuggingfaceRAGFinetuningDataset","title":"<code>HuggingfaceRAGFinetuningDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Thin wrapper over ~datasets.Dataset.</p> Source code in <code>src/fed_rag/utils/data/finetuning_datasets/huggingface.py</code> <pre><code>class HuggingfaceRAGFinetuningDataset(Dataset):\n    \"\"\"Thin wrapper over ~datasets.Dataset.\"\"\"\n\n    @classmethod\n    def from_inputs(\n        cls, input_ids: list[list[int]], target_ids: list[list[int]]\n    ) -&gt; Self:\n        return cls.from_dict(  # type: ignore[no-any-return]\n            {\"input_ids\": input_ids, \"target_ids\": target_ids}\n        )\n</code></pre>"},{"location":"references/#src.fed_rag.utils.data.finetuning_datasets.pytorch","title":"<code>pytorch</code>","text":"<p>PyTorch RAG Finetuning Dataset</p>"},{"location":"references/#src.fed_rag.utils.data.finetuning_datasets.pytorch.PyTorchRAGFinetuningDataset","title":"<code>PyTorchRAGFinetuningDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>PyTorch RAG Fine-Tuning Dataset Class.</p> <p>Parameters:</p> Name Type Description Default <code>Dataset</code> <code>_type_</code> <p>description</p> required Source code in <code>src/fed_rag/utils/data/finetuning_datasets/pytorch.py</code> <pre><code>class PyTorchRAGFinetuningDataset(Dataset):\n    \"\"\"PyTorch RAG Fine-Tuning Dataset Class.\n\n    Args:\n        Dataset (_type_): _description_\n    \"\"\"\n\n    def __init__(\n        self, input_ids: list[torch.Tensor], target_ids: list[torch.Tensor]\n    ):\n        self.input_ids = input_ids\n        self.target_ids = target_ids\n\n    def __len__(self) -&gt; int:\n        return len(self.input_ids)\n\n    def __getitem__(self, idx: int) -&gt; Any:\n        return self.input_ids[idx], self.target_ids[idx]\n</code></pre>"}]}